{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4, Parts F-H: Stochastic Gradient Descent with a Larger Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to write your code for problem 4 parts F-H by filling in the sections marked `# TODO` and running all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4F: Perform SGD with the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the functions below, you may re-use your code from parts 4C-E. Note that you can now modify your SGD function to return the final weight vector instead of the weights after every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(X, Y, w):\n",
    "    '''\n",
    "    Calculate the squared loss function.\n",
    "    \n",
    "    Inputs:\n",
    "        X: A (N, D) shaped numpy array containing the data points.\n",
    "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "        w: A (D, ) shaped numpy array containing the weight vector.\n",
    "    \n",
    "    Outputs:\n",
    "        The loss evaluated with respect to X, Y, and w.\n",
    "    '''\n",
    "    \n",
    "    #==============================================\n",
    "    # TODO: Implement the SGD loss function.\n",
    "    #==============================================\n",
    "    \n",
    "    pass\n",
    "\n",
    "def gradient(x, y, w):\n",
    "    '''\n",
    "    Calculate the gradient of the loss function with respect to\n",
    "    a single point (x, y), and using weight vector w.\n",
    "    \n",
    "    Inputs:\n",
    "        x: A (D, ) shaped numpy array containing a single data point.\n",
    "        y: The float label for the data point.\n",
    "        w: A (D, ) shaped numpy array containing the weight vector.\n",
    "        \n",
    "    Output:\n",
    "        The gradient of the loss with respect to x, y, and w. \n",
    "    '''\n",
    "    \n",
    "    #==============================================\n",
    "    # TODO: Implement the gradient of the loss function.\n",
    "    #==============================================    \n",
    "    \n",
    "    pass\n",
    "\n",
    "def SGD(X, Y, w_start, eta, N_epochs):\n",
    "    '''\n",
    "    Perform SGD using dataset (X, Y), initial weight vector w_start,\n",
    "    learning rate eta, and N_epochs epochs.\n",
    "    \n",
    "    Inputs:\n",
    "        X: A (N, D) shaped numpy array containing the data points.\n",
    "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "        w_start:  A (D, ) shaped numpy array containing the weight vector initialization.\n",
    "        eta: The step size.\n",
    "        N_epochs: The number of epochs (iterations) to run SGD.\n",
    "        \n",
    "    Outputs:\n",
    "        w: A (D, ) shaped array containing the final weight vector.\n",
    "        losses: A (N_epochs, ) shaped array containing the losses from all iterations.\n",
    "    '''\n",
    "    \n",
    "    #==============================================\n",
    "    # TODO: Implement the SGD algorithm.\n",
    "    #==============================================    \n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the dataset. In doing so, the following function may be helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: GeneratorExitiven as a string.\n",
    "    \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=1, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the dataset in `sgd_data.csv` and run SGD using the given parameters; print out the final weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==============================================\n",
    "# TODO:\n",
    "# (1) load the dataset\n",
    "# (2) run SGD using the given parameters\n",
    "# (3) print out the final weights.\n",
    "#=============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4G: Convergence of SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem examines the convergence of SGD for different learning rates. Please implement your code in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==============================================\n",
    "# TODO: create a plot showing the convergence\n",
    "# of SGD for the different learning rates.\n",
    "#=============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your code for computing the least-squares analytical solution below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==============================================\n",
    "# TODO: implement the least-squares\n",
    "# analytical solution.\n",
    "#=============================================="
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python3point5]",
   "language": "python",
   "name": "Python [python3point5]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
