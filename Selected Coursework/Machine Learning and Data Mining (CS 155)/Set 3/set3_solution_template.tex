\newif\ifshowsolutions
\showsolutionstrue
\input{preamble}

\usepackage{array}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}

\usepackage{bbm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% HEADER
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chead{
  {\vbox{
      \vspace{2mm}
      \large
      CS/CNS/EE 155 \hfill
      Philip Carr \hfill \\[1pt]
      Set 3\hfill
      %January $24^\text{th}$, 2019 \\
      January $30^\text{th}$, 2019 \\
    }
  }
}

\begin{document}
\pagestyle{fancy}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PROBLEM 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Decision Trees [30 Points]}
\materials{Lecture 5}

\problem[7] Consider the following data, where given information about some food you must
predict whether it is healthy:
\noindent
\begin{table}[H]
\centering
%\begin{tabular}{| C{0.5cm} | C{2cm} |}
\begin{tabular}{c | c c c | c}
\hline
No. & Package Type & Unit Price $>$ \$5 & Contains $>$ 5 grams of fat & Healthy? \\ \hline
1 & Canned & Yes & Yes & No \\
2 & Bagged & Yes & No & Yes \\
3 & Bagged & No & Yes & Yes \\
4 & Canned & No & No & Yes \\ \hline
\end{tabular}
\end{table}
\noindent
Train a decision tree by hand using top-down greedy induction. Use \textit{entropy} (with natural log) as the impurity measure. Since the data can be classified without error, the stopping criterion will be no impurity in the leaves.\\
\\
Submit a drawing of your tree showing the impurity reduction yielded by each split (including root) in  your decision tree.
\begin{solution}
\end{solution}


\newpage
\problem[4] Compared to a linear classifier, is a decision tree always preferred for classification
problems? If not, draw a simple 2-D dataset that can be perfectly classified by a simple linear classifier but which requires an overly complex decision tree to perfectly classify.
\begin{solution}
\end{solution}
\newpage


\problem[15] Consider the following 2D data set:
\noindent
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{2c_plot.png}
\end{figure}
\noindent
\subproblem[5] Suppose we train a decision tree on this dataset using top-down greedy induction, with the Gini index as the impurity measure. We define our stopping condition to be if no split of a node results in any reduction in impurity. Submit a drawing of the resulting tree. What is its classification error ((number of misclassified points) / (number of total points))?
\begin{subsolution}
\end{subsolution}
\newpage


\subproblem[5] Submit a drawing of a two-level decision tree that classifies the above dataset with zero classification error. (You don’t need to use any particular training algorithm to produce the tree.)\\
\\
Is there any impurity measure (i.e. any function that maps the data points under a particular node in a tree to a real number) that would have led top-down greedy induction with the same stopping condition to produce the tree you drew? If so, give an example of one, and briefly describe its pros and cons as an impurity measure for training decision trees in general (on arbitrary datasets).
\begin{subsolution}
\end{subsolution}
\newpage


\subproblem[5] Suppose there are 100 data points in some 2-D dataset. What is the largest number of unique thresholds (i.e., internal nodes) you might need in order to achieve zero classification training error (on the training set)? Please justify your answer.
\begin{subsolution}
\end{subsolution}
\newpage



\problem[4] Suppose in top-down greedy induction we want to split a leaf node that contains
N data points composed of D continuous features. What is the worst-case complexity (big-O in terms of N and D) of the number of possible splits we must consider in order to find the one that most reduces impurity? Please justify your answer.\\
\\
Note: Recall that at each node-splitting step in training a DT, you must consider all possible splits that you can make. While there are an infinite number of possible decision boundaries since we are using continuous features, there are not an infinite number of boundaries that result in unique child sets (which is what we mean by “split”).
\begin{solution}
\end{solution}
\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PROBLEM 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Overfitting Decision Trees [30 Points]}
\materials{Lecture 5}

In this problem, you will use the Diabetic Retinopathy Debrecen Data Set, which contains features extracted from images to determine whether or not the images contain signs of diabetic retinopathy. Additional information about this dataset can be found at the link below:\\
\\
\url{https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set}\\
\\
In the following question, your goal is to predict the diagnosis of diabetic retinopathy, which is the final column in the data matrix. Use the first 900 rows as training data, and the last 251 rows as validation data. Please feel free to use additional packages such as Scikit-Learn. Include your code in your submission.

\indent\problem[7] % indent for consistency 
Train a decision tree classifier using Gini as the impurity measure and minimal leaf
node size as early stopping criterion. Try different minimal leaf node sizes from 1 to 25 in increments of 1. Then, on a single plot, plot both training and test classification error versus leaf node size. To do this, fill in the \texttt{classification_err} and \texttt{eval_tree_based_model_min_samples} functions in the code template for this problem.
\begin{solution}
\end{solution}
\newpage


\problem[7] Train a decision tree classifier using Gini as the impurity measure and maximal tree
depth as early stopping criterion. Try different tree depths from 2 to 20 in increments of 1. Then, on a single plot, plot both training and test classification error versus tree depth. To do this, fill in the \texttt{eval_tree_-based_model_max_depth} function in the code template for this problem.
\begin{solution}
\end{solution}
\newpage


\problem[4] For both the minimal leaf node size and maximum depth parameters tested in
the last two questions, which parameter value minimizes the test error? What effects does early stopping have on the performance of a decision tree model? Please justify your answer based on the two plots you derived.
\begin{solution}
\end{solution}
\newpage


\indent\problem[2] % indent for consistency
Train a random forest classifier using Gini as the impurity measure, minimal leaf node size as early stopping criterion, and 1,000 trees in the forest. Try different node sizes from 1 to 25 in increments of 1. Then, on a single plot, plot both training and test classification error versus leaf node size.
\begin{solution}
\end{solution}
\newpage


\problem[2] Train a random forest classifier using Gini as the impurity measure, maximal tree
depth as early stopping criterion, and 1,000 trees in the forest. Try different tree depths from 2 to 20 in increments of 1. Then, on a single plot, plot both training and test classification error versus tree depth.
\begin{solution}
\end{solution}
\newpage


\problem[4] For both the minimal leaf node size and maximum depth parameters tested, which
parameter value minimizes the random forest test error? What effects does early stopping have on the performance of a random forest model? Please justify your answer based on the two plots you derived.
\begin{solution}
\end{solution}
\newpage


\problem[4] Do you observe any differences between the curves for the random forest and
decision tree plots? If so, explain what could account for these differences.
\begin{solution}
\end{solution}
\newpage





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PROBLEM 3 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{The AdaBoost Algorithm [40 points]}
\materials{Lecture 6}

In this problem, you will show that the choice of the $\alpha_t$ parameter in the AdaBoost algorithm corresponds to greedily minimizing an exponential upper bound on the loss term at each iteration.

\problem[3] Let $h_t : \mathbb{R}^m \rightarrow \{-1, 1\}$ be the weak classifier obtained at step $t$, and let $\alpha_t$ be its weight. Recall that the final classifier is
\[ H(x) = \text{sign}(f(x)) = \text{sign}\bigg(\sum_{i=1}^T \alpha_t h_t(x)\bigg). \]
Suppose $\{(x_1, y_1), ..., (x_N, y_N)\} \subset \mathbb{R}^m \times \{-1, 1\}$ is our training dataset. Show that the training set error of the final classifier can be bounded from above if an an exponential loss function is used:
\[ E = \dfrac{1}{N}\sum_{i=1}^N \exp(-y_i f(x_i)) \geq \dfrac{1}{N}\sum_{i=1}^{N} \mathbbm{1}(H(x_i)) \neq y_i), \]
where $\mathbbm{1}$ is the indicator function.
\begin{solution}
\end{solution}
\newpage


\problem[3] Find $D_{T+1}(i)$ in terms of $Z_t, \alpha_t, x_i, y_i$, and the classifier $h_t$, where $T$ is the last timestep and $t \in \{1, \dots , T\}$. Recall that $Z_t$ is the normalization factor for distribution $D_{t+1}$:
\[ Z_t = \sum_{i=1}^N D_t(i) \exp(-\alpha_t y_t h_t(x_i)). \]
\begin{solution}
\end{solution}
\newpage



\problem[2] Show that $E = \sum_{i=1}^N \frac{1}{N} e^{\sum_{t=1}^T -\alpha_t y_i h_t(x_i)}$:
\begin{solution}
\end{solution}
\newpage



\problem[5] Show that
\[ E = \prod_{t=1}^T Z_t. \]
\textit{\textbf{Hint:} Recall that $\sum_{i=1}^N D_t(i) = 1$ because D is a distribution.}
\begin{solution}
\end{solution}
\newpage


\problem[5] Show that the normalizer $Z_t$ can be written as
\[ Z_t = (1 - \epsilon_t)\exp(-\alpha_t) + \epsilon_t\exp(\alpha_t) \]
where $\epsilon_t$ is the training set error of weak classifier $h_t$ for the weighted dataset:
\[ \epsilon_t = \sum_{i=1}^N D_t(i) \mathbbm{1}(h_t(x_i) \neq y_i). \]
\begin{solution}
\end{solution}
\newpage



\problem[2] We derived all of this because it is hard to directly minimize the training set error,
but we can greedily minimize the upper bound $E$ on this error. Show that choosing $\alpha_t$ greedily to minimize $Z_t$ at each iteration leads to the choices in AdaBoost:
\[ \alpha_t^* = \dfrac{1}{2} \ln\Big(\dfrac{1-\epsilon_t}{\epsilon_t}\Big). \]
\begin{solution}
\end{solution}
\newpage



\problem[14] Implement the \texttt{GradientBoosting.fit()} and \texttt{AdaBoost.fit()} methods in
the notebook provided for you. Some important notes and guidelines follow:
\begin{enumerate}[$\bullet$]
\item For both methods, make sure to work with the class attributes provided to you. Namely, after\\
\texttt{GradientBoosting.fit()} is called, \texttt{self.clfs} should be appropriately filled with the \texttt{self.n_-clfs} trained weak hypotheses. Similarly, after \texttt{AdaBoost.fit()} is called, \texttt{self.clfs} and\\
\texttt{self.coefs}
should be appropriately filled with the \texttt{self.n_clfs} trained weak hypotheses and their coefficients, respectively.
\item \texttt{AdaBoost.fit()} should additionally return an $(N, T)$ shaped numpy array D such that \texttt{D[:, t]} contains $D_{t+1}$ for each $t \in \{0, \dots, \texttt{self.n_clfs}\}$.
\item For the \texttt{AdaBoost.fit()} method, \textbf{use the 0/1} loss instead of the exponential loss.
\item The only Sklearn classes that you may use in implementing your boosting fit functions are the DecisionTreeRegressor and DecisionTreeClassifier, not GradientBoostingRegressor.
\end{enumerate}
\begin{solution}
\end{solution}
\newpage


\problem[2] Describe and explain the behaviour of the loss curves for gradient boosting and for
AdaBoost. You should consider two kinds of behaviours: the smoothness of the curves and the final values that the curves approach.
\begin{solution}
\end{solution}
\newpage


\problem[2] Compare the final loss values of the two models. Which performed better on the
classification dataset?
\begin{solution}
\end{solution}
\newpage


\problem[2] For AdaBoost, where are the dataset weights the largest, and where are they the
smallest?\\
\\
\textit{\textbf{Hint:} Watch how the dataset weights change across time in the animation.}
\begin{solution}
\end{solution}
\newpage



\end{document}
