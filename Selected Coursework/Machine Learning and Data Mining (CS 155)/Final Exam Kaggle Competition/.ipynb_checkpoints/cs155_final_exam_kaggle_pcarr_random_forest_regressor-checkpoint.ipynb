{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 155 Final Exam Kaggle Competition\n",
    "# Philip Carr\n",
    "# Model: Random Forest Regressor (from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and divide it into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data.\n",
    "X = load_data(\"X_train.csv\")\n",
    "N = len(X)\n",
    "\n",
    "data = X[:, 3:-1]\n",
    "\n",
    "Y = load_data(\"y_train.csv\")\n",
    "label = Y\n",
    "\n",
    "train_percent = 70.\n",
    "train_size = int(N * train_percent / 100)\n",
    "\n",
    "# Randomly split the training data into training\n",
    "# and validation sets.\n",
    "random_order = np.random.permutation(np.arange(N))\n",
    "\n",
    "x_train = data[random_order[0:train_size]]\n",
    "y_train = label[random_order[0:train_size]]\n",
    "x_validation = data[random_order[train_size:]]\n",
    "y_validation = label[random_order[train_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.000e+00  1.200e+01  1.900e+01 ...  1.441e+03 -1.000e+00  0.000e+00]\n",
      " [ 6.000e+00  1.200e+01  2.500e+01 ...  1.350e+02 -1.000e+00  0.000e+00]\n",
      " [ 6.000e+00  1.200e+01  4.200e+01 ...  1.520e+03 -1.000e+00  0.000e+00]\n",
      " ...\n",
      " [ 3.000e+00  1.600e+01  3.900e+01 ... -1.000e+00 -1.000e+00  1.000e+00]\n",
      " [ 3.000e+00  1.600e+01  4.000e+01 ...  3.900e+01 -1.000e+00  0.000e+00]\n",
      " [ 3.000e+00  1.600e+01  4.000e+01 ...  5.620e+02 -1.000e+00  0.000e+00]]\n",
      "[ 0. 18.  3. ...  3.  0.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56490, 26)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   9.  32. ...  -1.  -1.   0.]\n",
      " [  0.  15.  40. ... 538.  -1.   0.]\n",
      " [  2.  15.  38. ...  -1.  -1.   0.]\n",
      " ...\n",
      " [  0.  11.  18. ... 132.  -1.   0.]\n",
      " [  3.   9.  56. ...  -1.  -1.   0.]\n",
      " [  4.   9.  50. ...  45.  -1.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 77.,  58., 105., ...,  47.,   6.,   3.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data.\n",
    "train_mean_array = np.zeros(len(x_train[0]))\n",
    "train_std_array = np.zeros(len(x_train[0]))\n",
    "std_nonzero_indices = []\n",
    "for j in range(len(x_train[0])):\n",
    "    train_mean_array[j] = np.mean(x_train[:,j])\n",
    "    train_std_array[j] = np.std(x_train[:,j])\n",
    "    if train_std_array[j] != 0:\n",
    "        std_nonzero_indices.append(j)\n",
    "        x_train[:,j] = \\\n",
    "            np.divide(x_train[:,j] - train_mean_array[j],\n",
    "                      train_std_array[j])\n",
    "    if np.std(x_validation[:,j]) != 0:\n",
    "        x_validation[:,j] = \\\n",
    "            np.divide(x_validation[:,j] - np.mean(x_validation[:,j]),\n",
    "                      np.std(x_validation[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "# Remove features from the data that have standard\n",
    "# deviation of 0 in the training set.\n",
    "print(std_nonzero_indices)\n",
    "# x_train = x_train[:, std_nonzero_indices]\n",
    "# x_validation = x_validation[:, std_nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_features = [1, 2, 3, 5, 6]\n",
    "x_train = x_train[:, good_features]\n",
    "x_validation = x_validation[:, good_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.21786677  0.18663729  1.          0.72407523 -0.4209398 ]\n",
      " [ 1.03393253  0.63612865  1.          0.72407523 -0.4209398 ]\n",
      " [ 1.03393253  0.52375581  1.          0.72407523 -0.4209398 ]\n",
      " ...\n",
      " [-0.467267   -0.59997257  1.         -1.38107196 -0.4209398 ]\n",
      " [-1.21786677  1.53511135  1.          0.72407523 -0.4209398 ]\n",
      " [-1.21786677  1.19799284  1.         -1.38107196 -0.4209398 ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 77.  58. 105. ...  47.   6.   3.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor Initialization and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "rf = RandomForestRegressor(n_estimators=1000, n_jobs=-1, max_features=4,\n",
    "                           max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_train = rf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 93.89532727,  94.77304028,  90.41630687, ...,  19.02957819,\n",
       "       105.09677497,  19.23597147])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_output_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.4621174041284911\n",
      "Train mse: 2610.165523031234\n"
     ]
    }
   ],
   "source": [
    "# Printing the accuracy of the model.\n",
    "train_score = rf.score(x_train, y_train)\n",
    "print('Train score:', train_score)\n",
    "# train_auc = roc_auc_score(y_train, y_output_train)\n",
    "# print('Train auc:', train_auc)\n",
    "train_mse = mean_squared_error(y_train, y_output_train)\n",
    "print('Train mse:', train_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 77.,  58., 105., ...,  47.,   6.,   3.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_lines = []\n",
    "for i in range(len(y_output_train)):\n",
    "    y_output_lines.append([i, y_output_train[i], y_train[i]])\n",
    "np.savetxt(\"train_output.csv\", y_output_lines, fmt='%d,%f,%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.44234682928989233\n",
      "Validation mse: 2637.114138814914\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of the model, according to the loss function specified in model.compile above.\n",
    "validation_score = rf.score(x_validation, y_validation)\n",
    "print('Validation score:', validation_score)\n",
    "y_output_validation = rf.predict(x_validation)\n",
    "# validation_auc = roc_auc_score(y_validation, y_output_validation)\n",
    "# print('Validation auc:', validation_auc)\n",
    "validation_mse = mean_squared_error(y_validation, y_output_validation)\n",
    "print('Validation mse:', validation_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_lines = []\n",
    "for i in range(len(y_output_validation)):\n",
    "    y_output_lines.append([i, y_output_validation[i], y_validation[i]])\n",
    "# np.savetxt(\"2008_validation_output.csv\", y_output_lines, fmt='%d,%f,%f')\n",
    "np.savetxt(\"validation_output.csv\", y_output_lines, fmt='%d,%f,%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2282.245656189637"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.mean(cross_val_score(rf, data, label, cv=2, scoring=\"roc_auc\"))\n",
    "np.mean(cross_val_score(rf, data, label, cv=2,\n",
    "                        scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2220.398004827284"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.mean(cross_val_score(rf, data, label, cv=3, scoring=\"roc_auc\"))\n",
    "np.mean(cross_val_score(rf, data, label, cv=3,\n",
    "                        scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2041.474312603059"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.mean(cross_val_score(rf, data, label, cv=4, scoring=\"roc_auc\"))\n",
    "np.mean(cross_val_score(rf, data, label, cv=4,\n",
    "                        scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2008 test data.\n",
    "X_test = load_data(\"X_test.csv\")\n",
    "ids = np.arange(len(X_test))\n",
    "x_test = X_test[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data.\n",
    "for j in range(len(x_test[0])):\n",
    "    test_std = np.std(x_test[:,j])\n",
    "    if test_std != 0:\n",
    "        x_test[:,j] = \\\n",
    "            np.divide(x_test[:,j] - np.mean(x_test[:,j]),\n",
    "                      np.std(x_test[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features from the data that have standard\n",
    "# deviation of 0 in the training set.\n",
    "x_test = x_test[:, std_nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_lines2 = []\n",
    "for i in range(len(y_output)):\n",
    "    y_output_lines2.append([i, y_output[i]])\n",
    "np.savetxt(\"submission.csv\", y_output_lines2, fmt='%d,%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Output 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the 2012 test data.\n",
    "# X_test2 = load_data(\"test_2012.csv\")\n",
    "# ids2 = X_test2[:,0]\n",
    "# x_test2 = X_test2[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalizing the data.\n",
    "# for j in range(len(x_test2[0])):\n",
    "#     test_std = np.std(x_test2[:,j])\n",
    "#     if test_std != 0:\n",
    "#         x_test2[:,j] = \\\n",
    "#             np.divide(x_test2[:,j] - np.mean(x_test2[:,j]),\n",
    "#                       np.std(x_test2[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove features from the data that have standard\n",
    "# # deviation of 0 in the training set.\n",
    "# x_test2 = x_test2[:, std_nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_output2 = rf.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_output_lines3 = []\n",
    "# for i in range(len(y_output2)):\n",
    "#     y_output_lines3.append([i, y_output2[i]])\n",
    "# np.savetxt(\"2012_submission.csv\", y_output_lines3, fmt='%d,%f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
