{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 155 Final Exam Kaggle Competition\n",
    "# Philip Carr\n",
    "# Model: XGBoost (from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and divide it into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data.\n",
    "X = load_data(\"X_train.csv\")\n",
    "N = len(X)\n",
    "\n",
    "data = X[:, 3:]\n",
    "\n",
    "Y = load_data(\"y_train.csv\")\n",
    "label = Y\n",
    "\n",
    "train_percent = 70.\n",
    "train_size = int(N * train_percent / 100)\n",
    "\n",
    "# Randomly split the training data into training\n",
    "# and validation sets.\n",
    "random_order = np.random.permutation(np.arange(N))\n",
    "\n",
    "x_train = data[random_order[0:train_size]]\n",
    "y_train = label[random_order[0:train_size]]\n",
    "x_validation = data[random_order[train_size:]]\n",
    "y_validation = label[random_order[train_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6. 12. 19. ... -1.  0.  1.]\n",
      " [ 6. 12. 25. ... -1.  0.  1.]\n",
      " [ 6. 12. 42. ... -1.  0.  1.]\n",
      " ...\n",
      " [ 3. 16. 39. ... -1.  1.  1.]\n",
      " [ 3. 16. 40. ... -1.  0. 67.]\n",
      " [ 3. 16. 40. ... -1.  0. 53.]]\n",
      "[ 0. 18.  3. ...  3.  0.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56490, 26)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4. 15.  8.  1.  0.]\n",
      " [ 2.  9.  1.  1.  0.]\n",
      " [ 2. 15. 28.  1.  0.]\n",
      " [ 1.  9.  0.  1.  0.]\n",
      " [ 2.  9. 25.  1.  0.]]\n",
      "0 0 4.0\n",
      "1 0 15.0\n",
      "2 0 8.0\n",
      "9 0 229.0\n",
      "10 11 10.0\n",
      "11 961 10.0\n",
      "12 22519 4.0\n",
      "13 0 -1.0\n",
      "19 0 -1.0\n",
      "20 0 -1.0\n",
      "21 4 2.0\n",
      "22 0 11.0\n",
      "[3, 4, 5, 6, 7, 8, 14, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "# print(x_train[:5,:5])\n",
    "# categorical_features = []\n",
    "# for j in range(len(x_train[0])):\n",
    "#     is_categorical = True\n",
    "#     for i in range(len(x_train)):\n",
    "#         if int(x_train[i,j]) not in [0, 1]:\n",
    "#             print(j,i,x_train[i,j])\n",
    "#             is_categorical = False\n",
    "#             break\n",
    "#     if is_categorical:\n",
    "#         categorical_features.append(j)\n",
    "# print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "\n",
    "# total_cols = len(x_train[0]) + len(categorical_features)\n",
    "# new_x_train = np.zeros(shape=(len(x_train), total_cols))\n",
    "# new_x_validation = np.zeros(shape=(len(x_validation), total_cols))\n",
    "\n",
    "# count = 0\n",
    "# for j in range(total_cols):\n",
    "#     if j not in categorical_features:\n",
    "#         new_x_train[:,j] = x_train[:,j]\n",
    "#         new_x_validation[:,j] = x_validation[:,j]\n",
    "#     else:\n",
    "#         feature_cols_train = to_categorical(x_train[:,j])\n",
    "#         new_x_train[]\n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4. 15.  8. ... -1.  0. 11.]\n",
      " [ 2.  9.  1. ... -1.  0.  8.]\n",
      " [ 2. 15. 28. ... -1.  0. 67.]\n",
      " ...\n",
      " [ 4. 15.  7. ... -1.  0. -1.]\n",
      " [ 4. 15. 12. ... -1.  0. -1.]\n",
      " [ 4.  9. 18. ... -1.  0. 27.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39543, 23)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  0.,  2., ...,  0., 94.,  3.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set missing values to column (feature) medians\n",
    "# for j in range(len(x_train[0])):\n",
    "#     col_median_train = np.median(x_train[:,j])\n",
    "#     col_median_validation = np.median(x_validation[:,j])\n",
    "#     for i in range(len(x_train)):\n",
    "#         if x_train[i,j] == -1:\n",
    "#             x_train[i,j] = col_median_train\n",
    "#     for i in range(len(x_validation)):\n",
    "#         if x_validation[i,j] == -1:\n",
    "#             x_validation[i,j] = col_median_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data.\n",
    "train_mean_array = np.zeros(len(x_train[0]))\n",
    "train_std_array = np.zeros(len(x_train[0]))\n",
    "std_nonzero_indices = []\n",
    "for j in range(len(x_train[0])):\n",
    "    train_mean_array[j] = np.mean(x_train[:,j])\n",
    "    train_std_array[j] = np.std(x_train[:,j])\n",
    "    if train_std_array[j] != 0:\n",
    "        std_nonzero_indices.append(j)\n",
    "        x_train[:,j] = \\\n",
    "            np.divide(x_train[:,j] - train_mean_array[j],\n",
    "                      train_std_array[j])\n",
    "    if np.std(x_validation[:,j]) != 0:\n",
    "        x_validation[:,j] = \\\n",
    "            np.divide(x_validation[:,j] - np.mean(x_validation[:,j]),\n",
    "                      np.std(x_validation[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "# Remove features from the data that have standard\n",
    "# deviation of 0 in the training set.\n",
    "print(std_nonzero_indices)\n",
    "x_train = x_train[:, std_nonzero_indices]\n",
    "x_validation = x_validation[:, std_nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_features = [1, 2, 3, 4, 5, 9, 10, 14, 15, 19, 21, 22]\n",
    "# x_train = x_train[:, good_features]\n",
    "# x_validation = x_validation[:, good_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.01273156  1.03439973 -1.16494235 ... -0.0217789  -0.21822131\n",
      "  -0.45997069]\n",
      " [-0.20076028 -1.21802424 -1.55858225 ... -0.0217789  -0.21822131\n",
      "  -0.60767234]\n",
      " [-0.20076028  1.03439973 -0.04025693 ... -0.0217789  -0.21822131\n",
      "   2.29712674]\n",
      " ...\n",
      " [ 1.01273156  1.03439973 -1.22117662 ... -0.0217789  -0.21822131\n",
      "  -0.45997069]\n",
      " [ 1.01273156  1.03439973 -0.94000527 ... -0.0217789  -0.21822131\n",
      "  -0.45997069]\n",
      " [ 1.01273156 -1.21802424 -0.60259964 ... -0.0217789  -0.21822131\n",
      "   0.32777143]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39543, 22)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  0.  2. ...  0. 94.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dvalidation = xgb.DMatrix(x_validation, label=y_validation)\n",
    "#dtest = xgb.DMatrix(x_test)\n",
    "# specify parameters via map\n",
    "param = {'max_depth':3, 'eta':0.5, 'silent':1,\n",
    "         'objective':'reg:linear', 'eval_metric':'rmse',\n",
    "         'scale_pos_rate':1, 'n_estimators':1000}\n",
    "num_round = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bst = None\n",
    "# for num_r in range(2, 21):\n",
    "#     #print(num_r)\n",
    "#     #print(xgb.cv(param, dtrain, num_r, 5))\n",
    "    \n",
    "#     #print(xgb.cv(param, dtrain, num_round, 5))\n",
    "#     print()\n",
    "#     print(num_r)\n",
    "#     bst = xgb.train(param, dtrain, num_boost_round=num_r)\n",
    "#     # make prediction\n",
    "    \n",
    "#     preds = bst.predict(dtrain)\n",
    "#     print(mean_squared_error(y_train, preds))\n",
    "    \n",
    "#     preds = bst.predict(dvalidation)\n",
    "#     print(mean_squared_error(y_validation, preds))\n",
    "    \n",
    "#     #preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Initialization and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to new file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   26.0s\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:   33.7s\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:   37.4s\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:   46.5s\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  1.2min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:  1.3min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:  1.5min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  1.8min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:  2.2min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  2.5min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:  2.8min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:  3.0min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:  3.6min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:  4.0min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  21 | elapsed:  4.2min remaining:  1.7min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done  16 out of  21 | elapsed:  4.8min remaining:  1.5min\n",
      "Memmaping (shape=(39543, 22), dtype=float64) to old file C:\\Users\\Phil\\AppData\\Local\\Temp\\joblib_memmaping_pool_33276_1890688592864\\33276-1890623909728-67d6a6e5dc33169ea1fa36f5f81eae52.pkl\n",
      "Pickling array (shape=(39543,), dtype=float64).\n",
      "Pickling array (shape=(26362,), dtype=int32).\n",
      "Pickling array (shape=(13181,), dtype=int32).\n",
      "[Parallel(n_jobs=4)]: Done  17 out of  21 | elapsed:  5.4min remaining:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  18 out of  21 | elapsed:  5.7min remaining:   57.1s\n",
      "[Parallel(n_jobs=4)]: Done  19 out of  21 | elapsed:  6.2min remaining:   39.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  21 out of  21 | elapsed:  6.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  21 out of  21 | elapsed:  6.9min finished\n",
      "{'n_estimators': 300} -1044.9487559310612\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb1 = XGBRegressor(max_depth=6, learning_rate=0.1, n_estimators=300,\n",
    "                    silent=True, objective='reg:linear',\n",
    "                    booster='dart', n_jobs=6, nthread=None,\n",
    "                    gamma=1, min_child_weight=4, max_delta_step=0,\n",
    "                    subsample=0.8, colsample_bytree=0.8,\n",
    "                    colsample_bylevel=1, reg_alpha=0.20, \n",
    "                    reg_lambda=1, scale_pos_weight=1, \n",
    "                    base_score=0.5, random_state=0,\n",
    "                    seed=10, missing=None, importance_type='gain')\n",
    "xgb1 = XGBRegressor(max_depth=6, learning_rate=0.1, n_estimators=300,\n",
    "                    silent=True, objective='reg:linear',\n",
    "                    booster='gbtree', n_jobs=4, nthread=None,\n",
    "                    gamma=0, min_child_weight=6, max_delta_step=0,\n",
    "                    subsample=0.8, colsample_bytree=0.8,\n",
    "                    colsample_bylevel=1, reg_alpha=0.20, \n",
    "                    reg_lambda=1, scale_pos_weight=1, \n",
    "                    base_score=0.5, random_state=0, \n",
    "                    seed=None, missing=None, importance_type='gain')\n",
    "xgb1.fit(x_train, y_train, eval_metric='rmse')\n",
    "\n",
    "# param_test1 = {\n",
    "#  'max_depth':range(4,7),\n",
    "#  'min_child_weight':range(4,7)\n",
    "# }  # result: max_depth = 5, max_child_weight = 6 (old)\n",
    "# param_test2 = {\n",
    "#  'n_estimators':range(150, 310, 25)\n",
    "# } # result: n_estimators = 200 (old)\n",
    "# param_test3 = {\n",
    "#     'max_depth':range(4,7),\n",
    "#     'min_child_weight':range(4,7),\n",
    "#     'n_estimators':range(150, 310, 25)\n",
    "# } # result: max_depth = 6, max_child_weight = 4, n_estimators = 300\n",
    "# param_test4 = {\n",
    "#     \"objective\":[\"reg:linear\"],\n",
    "#     'learning_rate':[0.1, 0.01],\n",
    "#     'booster':[\"gbtree\", \"gblinear\", \"dart\"],\n",
    "#     \"gamma\":[0, 1, 0.1, 0.01],\n",
    "#     \"max_delta_step\":[0, 1]\n",
    "# } # result: {'booster': 'dart', 'gamma': 1, 'learning_rate': 0.1, \n",
    "# # 'max_delta_step': 0, 'objective': 'reg:linear'}\n",
    "# param_test5= {\n",
    "#     \"lambda\":[0, 1, 10, 20, 100],\n",
    "#     \"alpha\":[0, 1, 10, 20, 100],\n",
    "#     \"tree_method\":[\"auto\"]\n",
    "# }\n",
    "# param_test6= {\n",
    "#     \"subsample\":[0.6, 0.8, 1],\n",
    "#     \"colsample_bytree\":[0.6, 0.8, 1],\n",
    "#     \"colsample_bylevel\":[0.6, 0.8, 1],\n",
    "#     \"colsample_bynode\":[0.6, 0.8, 1]\n",
    "# }\n",
    "# gsearch1 = GridSearchCV(\n",
    "#     estimator = XGBRegressor( learning_rate =0.1, n_estimators=300,\n",
    "#                              max_depth=6, min_child_weight=4, gamma=1,\n",
    "#                              subsample=0.8, colsample_bytree=0.8,\n",
    "#                              objective= 'reg:linear', nthread=4,\n",
    "#                              booster=\"dart\", max_delta_step=0,\n",
    "#                              scale_pos_weight=1, seed=27),\n",
    "#     param_grid = param_test2, scoring='neg_mean_squared_error',\n",
    "#     n_jobs=4,iid=False, cv=3, verbose=999)\n",
    "# gsearch1.fit(x_train, y_train)\n",
    "# print(gsearch1.best_params_, gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time [ 29.35117141  42.54057837  56.82270495  73.99692098  86.77332314\n",
      " 105.45763954 106.90444795]\n",
      "std_fit_time [ 3.7598946   1.58781814  2.54549949  1.91874789  0.56474188  0.99593386\n",
      " 13.0936564 ]\n",
      "mean_score_time [0.12134266 0.13397519 0.14461295 0.122672   0.11170117 0.14162143\n",
      " 0.16555738]\n",
      "std_score_time [0.02774981 0.02746279 0.02750698 0.02411489 0.01340439 0.01999621\n",
      " 0.05148247]\n",
      "param_n_estimators [150 175 200 225 250 275 300]\n",
      "params [{'n_estimators': 150}, {'n_estimators': 175}, {'n_estimators': 200}, {'n_estimators': 225}, {'n_estimators': 250}, {'n_estimators': 275}, {'n_estimators': 300}]\n",
      "split0_test_score [-1078.92770956 -1062.08743978 -1053.14916671 -1045.0364855\n",
      " -1039.05719964 -1035.36826096 -1030.52384493]\n",
      "split1_test_score [-1093.80299333 -1076.84385662 -1063.87563929 -1054.41258589\n",
      " -1043.43292015 -1039.66784203 -1036.69652592]\n",
      "split2_test_score [-1110.12946633 -1098.86526037 -1091.04196942 -1081.3741436\n",
      " -1080.00148588 -1073.55317379 -1067.62589695]\n",
      "mean_test_score [-1094.28672307 -1079.26551892 -1069.35559181 -1060.274405\n",
      " -1054.16386856 -1049.52975892 -1044.94875593]\n",
      "std_test_score [12.74265546 15.11181344 15.94759196 15.40296598 18.35708009 17.07756707\n",
      " 16.2319652 ]\n",
      "rank_test_score [7 6 5 4 3 2 1]\n",
      "split0_train_score [-931.74865425 -896.42710839 -867.40309614 -838.53941677 -816.79507709\n",
      " -797.73855923 -777.15402963]\n",
      "split1_train_score [-949.63533085 -909.08394167 -875.02377767 -846.60868702 -818.08282564\n",
      " -796.01357645 -770.74181098]\n",
      "split2_train_score [-916.39845983 -886.32689627 -856.56506468 -826.63109649 -802.32693097\n",
      " -780.03614762 -755.8615768 ]\n",
      "mean_train_score [-932.59414831 -897.27931544 -866.33064616 -837.25973342 -812.40161123\n",
      " -791.2627611  -767.91913914]\n",
      "std_train_score [13.58206032  9.31004732  7.57379839  8.20586063  7.14324673  7.96958924\n",
      "  8.91880949]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# for key in gsearch1.cv_results_:\n",
    "#     print(key, gsearch1.cv_results_[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_train = xgb1.predict(x_train)\n",
    "\n",
    "y_output_validation = xgb1.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_output_train = gsearch1.predict(x_train)\n",
    "\n",
    "# y_output_validation = gsearch1.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.5592256,  1.0467567, 12.496606 , ..., 10.44915  , 61.841503 ,\n",
       "       -1.5584807], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_output_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mse: 822.2288875386835\n"
     ]
    }
   ],
   "source": [
    "# Printing the accuracy of the model.\n",
    "# train_score = rf.score(x_train, y_train)\n",
    "# print('Train score:', train_score)\n",
    "# train_auc = roc_auc_score(y_train, y_output_train)\n",
    "# print('Train auc:', train_auc)\n",
    "train_mse = mean_squared_error(y_train, y_output_train)\n",
    "print('Train mse:', train_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  0.,  2., ...,  0., 94.,  3.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_lines = []\n",
    "for i in range(len(y_output_train)):\n",
    "    y_output_lines.append([i, y_output_train[i], y_train[i]])\n",
    "np.savetxt(\"train_output.csv\", y_output_lines, fmt='%d,%f,%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 1811.3958576982693\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of the model, according to the loss function specified in model.compile above.\n",
    "# validation_score = rf.score(x_validation, y_validation)\n",
    "# print('Validation score:', validation_score)\n",
    "# y_output_validation = rf.predict(x_validation)\n",
    "# validation_auc = roc_auc_score(y_validation, y_output_validation)\n",
    "# print('Validation auc:', validation_auc)\n",
    "validation_mse = mean_squared_error(y_validation, y_output_validation)\n",
    "print('Validation mse:', validation_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_lines = []\n",
    "for i in range(len(y_output_validation)):\n",
    "    y_output_lines.append([i, y_output_validation[i], y_validation[i]])\n",
    "# np.savetxt(\"2008_validation_output.csv\", y_output_lines, fmt='%d,%f,%f')\n",
    "np.savetxt(\"validation_output.csv\", y_output_lines, fmt='%d,%f,%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(cross_val_score(rf, data, label, cv=2, scoring=\"roc_auc\"))\n",
    "# np.mean(cross_val_score(rf, data, label, cv=2,\n",
    "#                         scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(cross_val_score(rf, data, label, cv=3, scoring=\"roc_auc\"))\n",
    "# np.mean(cross_val_score(rf, data, label, cv=3,\n",
    "#                         scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(cross_val_score(rf, data, label, cv=4, scoring=\"roc_auc\"))\n",
    "# np.mean(cross_val_score(rf, data, label, cv=4,\n",
    "#                         scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2008 test data.\n",
    "X_test = load_data(\"X_test.csv\")\n",
    "ids = np.arange(len(X_test))\n",
    "x_test = X_test[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set missing values to column (feature) medians\n",
    "for j in range(len(x_test[0])):\n",
    "    col_median_test = np.median(x_test[:,j])\n",
    "    for i in range(len(x_test)):\n",
    "        if x_test[i,j] == -1:\n",
    "            x_test[i,j] = col_median_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data.\n",
    "for j in range(len(x_test[0])):\n",
    "    test_std = np.std(x_test[:,j])\n",
    "    if test_std != 0:\n",
    "        x_test[:,j] = \\\n",
    "            np.divide(x_test[:,j] - np.mean(x_test[:,j]),\n",
    "                      np.std(x_test[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37661, 23)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.38537524  1.3166926   0.65127962  1.         -0.23222022 -1.15704656\n",
      " -0.41129133  2.23731563 -0.26412652  0.10250787  1.69230879 -0.03091436\n",
      "  0.         -0.22427582  0.92804801 -0.81476327 -0.09169316 -0.23893834\n",
      " -0.03754031  1.33763082 -0.02107569  0.70466197 -0.90230796]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "print(std_nonzero_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features from the data that have standard\n",
    "# deviation of 0 in the training set.\n",
    "x_test = x_test[:, std_nonzero_indices]\n",
    "\n",
    "# x_test = x_test[:, good_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37661, 22)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.38537524  1.3166926   0.65127962 -0.23222022 -1.15704656 -0.41129133\n",
      "  2.23731563 -0.26412652  0.10250787  1.69230879 -0.03091436  0.\n",
      " -0.22427582  0.92804801 -0.81476327 -0.09169316 -0.23893834 -0.03754031\n",
      "  1.33763082 -0.02107569  0.70466197 -0.90230796]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output = xgb1.predict(x_test)\n",
    "\n",
    "# y_output = gsearch1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_lines2 = []\n",
    "for i in range(len(y_output)):\n",
    "    y_output_lines2.append([i, y_output[i]])\n",
    "np.savetxt(\"submission.csv\", y_output_lines2, fmt='%d,%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Output 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the 2012 test data.\n",
    "# X_test2 = load_data(\"test_2012.csv\")\n",
    "# ids2 = X_test2[:,0]\n",
    "# x_test2 = X_test2[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalizing the data.\n",
    "# for j in range(len(x_test2[0])):\n",
    "#     test_std = np.std(x_test2[:,j])\n",
    "#     if test_std != 0:\n",
    "#         x_test2[:,j] = \\\n",
    "#             np.divide(x_test2[:,j] - np.mean(x_test2[:,j]),\n",
    "#                       np.std(x_test2[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove features from the data that have standard\n",
    "# # deviation of 0 in the training set.\n",
    "# x_test2 = x_test2[:, std_nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_output2 = rf.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_output_lines3 = []\n",
    "# for i in range(len(y_output2)):\n",
    "#     y_output_lines3.append([i, y_output2[i]])\n",
    "# np.savetxt(\"2012_submission.csv\", y_output_lines3, fmt='%d,%f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
