{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 155 Miniproject 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "# For the AUC metric\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505\n",
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and divide it into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_data(\"train_2008.csv\")\n",
    "N = len(X)\n",
    "\n",
    "data = X[:, 3:-1]\n",
    "label = X[:, -1]\n",
    "\n",
    "train_percent = 70.\n",
    "train_size = int(N * train_percent / 100)\n",
    "\n",
    "x_train = data[0:train_size]\n",
    "y_train = label[0:train_size]\n",
    "x_validation = data[train_size:]\n",
    "y_validation = label[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(N)\n",
    "# print(train_size)\n",
    "print(np.shape(X))\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels.\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train)\n",
    "y_validation = keras.utils.np_utils.to_categorical(y_validation)\n",
    "\n",
    "class_weight = {0: np.sum(y_train[:,0]),\n",
    "                1: np.sum(y_train[:,1])}\n",
    "\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# don't forget to NORMALIZE\n",
    "train_mean_array = np.zeros(len(x_train[0]))\n",
    "train_std_array = np.zeros(len(x_train[0]))\n",
    "std_nonzero_indices = []\n",
    "for j in range(len(x_train[0])):\n",
    "    train_mean_array[j] = np.mean(x_train[:,j])\n",
    "    train_std_array[j] = np.std(x_train[:,j])\n",
    "    if train_std_array[j] != 0:\n",
    "        std_nonzero_indices.append(j)\n",
    "        x_train[:,j] = \\\n",
    "            np.divide(x_train[:,j] - train_mean_array[j],\n",
    "                      train_std_array[j])\n",
    "    if np.std(x_validation[:,j]) != 0:\n",
    "        x_validation[:,j] = \\\n",
    "            np.divide(x_validation[:,j] - np.mean(x_validation[:,j]),\n",
    "                      np.std(x_validation[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:, std_nonzero_indices]\n",
    "x_validation = x_validation[:, std_nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.61795939  0.38451965 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]\n",
      " [-0.61795939  0.38451965 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]\n",
      " [-0.61795939 -2.60061808 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]\n",
      " ...\n",
      " [ 0.57602003  0.38451965 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]\n",
      " [-0.61795939  0.38451965 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]\n",
      " [-0.61795939 -2.60061808 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the model here given the constraints in the problem.\n",
    "model = Sequential()\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_callbacks = [EarlyStopping(monitor='auc_roc', patience=300, verbose=1, mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(loss='mse',\n",
    "               optimizer='rmsprop', metrics=['accuracy', auc_roc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-d689dba3be55>:4: streaming_auc (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.metrics.auc. Note that the order of the labels and predictions arguments has been switched.\n",
      "Epoch 1/5\n",
      "45266/45266 [==============================] - 9s 203us/step - loss: 2907.9118 - acc: 0.7446 - auc_roc: 0.7485\n",
      "Epoch 2/5\n",
      "45266/45266 [==============================] - 5s 113us/step - loss: 2576.6730 - acc: 0.7494 - auc_roc: 0.7584\n",
      "Epoch 3/5\n",
      "45266/45266 [==============================] - 5s 114us/step - loss: 2378.6501 - acc: 0.7535 - auc_roc: 0.7790\n",
      "Epoch 4/5\n",
      "45266/45266 [==============================] - 5s 113us/step - loss: 2347.3245 - acc: 0.7562 - auc_roc: 0.7939\n",
      "Epoch 5/5\n",
      "45266/45266 [==============================] - 5s 113us/step - loss: 2333.6286 - acc: 0.7590 - auc_roc: 0.8044\n"
     ]
    }
   ],
   "source": [
    "# fit = model.fit(x_train, y_train, batch_size=64, epochs=20,\n",
    "#     verbose=1, callbacks=my_callbacks)\n",
    "fit = model.fit(x_train, y_train, batch_size=64, epochs=5,\n",
    "    verbose=1, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x000002208E205860>\n",
      "(None, 1000)\n",
      "<keras.layers.core.Activation object at 0x000002208E205518>\n",
      "(None, 1000)\n",
      "<keras.layers.core.Dropout object at 0x000002208E205E80>\n",
      "(None, 1000)\n",
      "<keras.layers.core.Dense object at 0x000002208E205D30>\n",
      "(None, 500)\n",
      "<keras.layers.core.Activation object at 0x000002208E2059E8>\n",
      "(None, 500)\n",
      "<keras.layers.core.Dropout object at 0x000002208E205F28>\n",
      "(None, 500)\n",
      "<keras.layers.core.Dense object at 0x000002208E205F60>\n",
      "(None, 1000)\n",
      "<keras.layers.core.Activation object at 0x000002208E205F98>\n",
      "(None, 1000)\n",
      "<keras.layers.core.Dense object at 0x000002208E205C88>\n",
      "(None, 2)\n",
      "<keras.layers.core.Activation object at 0x000002208E205470>\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "# why don't we take a look at the layers and outputs\n",
    "# note: `None` in the first dimension means it can take any batch_size!\n",
    "for i in range(len(model.layers)):\n",
    "    layer = model.layers[i]\n",
    "    print(layer)\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370502"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our model has some # of parameters:\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              367000    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              501000    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 2002      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,370,502\n",
      "Trainable params: 1,370,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Printing a summary of the layers and weights in the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc', 'auc_roc']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that our model outputs two eval params:\n",
    "# 1. loss (categorical cross-entropy)\n",
    "# 2. accuracy\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.17230758151070838\n",
      "Train accuracy: 0.7649670834543006\n",
      "Train AUC: 0.8125230741291226\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of the model, according to the loss function specified in model.compile above.\n",
    "train_score = model.evaluate(x=x_train, y=y_train, verbose=0)\n",
    "print('Train score:', train_score[0])\n",
    "print('Train accuracy:', train_score[1])\n",
    "print('Train AUC:', train_score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_train = model.predict(x_train, batch_size=None, verbose=0, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_output_train)):\n",
    "    y_output_train[i] = [i, y_output_train[i][1]]\n",
    "np.savetxt(\"2008_train_output.csv\", y_output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.2283090417851837\n",
      "Validation accuracy: 0.7401164888469259\n",
      "Validation AUC: 0.8120945927550034\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of the model, according to the loss function specified in model.compile above.\n",
    "validation_score = model.evaluate(x=x_validation, y=y_validation, verbose=0)\n",
    "print('Validation score:', validation_score[0])\n",
    "print('Validation accuracy:', validation_score[1])\n",
    "print('Validation AUC:', validation_score[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load_data(\"test_2008.csv\")\n",
    "ids = X_test[:,0]\n",
    "\n",
    "x_test = X[:, 3:-1]\n",
    "y_test = X[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = keras.utils.np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to NORMALIZE\n",
    "# std_nonzero_indices = []\n",
    "for j in range(len(x_test[0])):\n",
    "    test_std = np.std(x_test[:,j])\n",
    "    if test_std != 0:\n",
    "        # std_nonzero_indices.append(j)\n",
    "        x_test[:,j] = \\\n",
    "            np.divide(x_test[:,j] - np.mean(x_test[:,j]),\n",
    "                      np.std(x_test[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test[:, std_nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.22785497065347515\n",
      "Test accuracy: 0.7446147184799109\n",
      "Test AUC: 0.7986823468794377\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of the model, according to the loss function specified in model.compile above.\n",
    "test_score = model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "print('Test score:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])\n",
    "print('Test AUC:', test_score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predict in module keras.engine.training:\n",
      "\n",
      "predict(x, batch_size=None, verbose=0, steps=None) method of keras.engine.sequential.Sequential instance\n",
      "    Generates output predictions for the input samples.\n",
      "    \n",
      "    Computation is done in batches.\n",
      "    \n",
      "    # Arguments\n",
      "        x: The input data, as a Numpy array\n",
      "            (or list of Numpy arrays if the model has multiple inputs).\n",
      "        batch_size: Integer. If unspecified, it will default to 32.\n",
      "        verbose: Verbosity mode, 0 or 1.\n",
      "        steps: Total number of steps (batches of samples)\n",
      "            before declaring the prediction round finished.\n",
      "            Ignored with the default value of `None`.\n",
      "    \n",
      "    # Returns\n",
      "        Numpy array(s) of predictions.\n",
      "    \n",
      "    # Raises\n",
      "        ValueError: In case of mismatch between the provided\n",
      "            input data and the model's expectations,\n",
      "            or in case a stateful model receives a number of samples\n",
      "            that is not a multiple of the batch size.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output = model.predict(x_test, batch_size=None, verbose=0, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_output)):\n",
    "    y_output[i] = [i, y_output[i][1]]\n",
    "np.savetxt(\"2008_submission.csv\", y_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
