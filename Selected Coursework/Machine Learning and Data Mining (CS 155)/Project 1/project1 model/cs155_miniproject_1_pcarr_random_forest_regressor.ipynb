{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 155 Miniproject 1\n",
    "# Philip Carr\n",
    "# Model: Random Forest Regressor (from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and divide it into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data.\n",
    "X = load_data(\"train_2008.csv\")\n",
    "N = len(X)\n",
    "\n",
    "data = X[:, 3:-1]\n",
    "label = X[:, -1]\n",
    "\n",
    "train_percent = 70.\n",
    "train_size = int(N * train_percent / 100)\n",
    "\n",
    "# Randomly split the training data into training\n",
    "# and validation sets.\n",
    "random_order = np.random.permutation(np.arange(N))\n",
    "\n",
    "x_train = data[random_order[0:train_size]]\n",
    "y_train = label[random_order[0:train_size]]\n",
    "x_validation = data[random_order[train_size:]]\n",
    "y_validation = label[random_order[train_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64667, 383)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1. 201.   0. ...   0.   0.   0.]\n",
      " [  1. 201.   0. ...   0.   0.   0.]\n",
      " [  1. 201.   0. ...   0.   0.   0.]\n",
      " ...\n",
      " [  1. 201.   0. ...   0.   0.   0.]\n",
      " [  1. 201.   0. ...   0.   0.   0.]\n",
      " [  1. 201.   0. ...   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data.\n",
    "train_mean_array = np.zeros(len(x_train[0]))\n",
    "train_std_array = np.zeros(len(x_train[0]))\n",
    "std_nonzero_indices = []\n",
    "for j in range(len(x_train[0])):\n",
    "    train_mean_array[j] = np.mean(x_train[:,j])\n",
    "    train_std_array[j] = np.std(x_train[:,j])\n",
    "    if train_std_array[j] != 0:\n",
    "        std_nonzero_indices.append(j)\n",
    "        x_train[:,j] = \\\n",
    "            np.divide(x_train[:,j] - train_mean_array[j],\n",
    "                      train_std_array[j])\n",
    "    if np.std(x_validation[:,j]) != 0:\n",
    "        x_validation[:,j] = \\\n",
    "            np.divide(x_validation[:,j] - np.mean(x_validation[:,j]),\n",
    "                      np.std(x_validation[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features from the data that have standard\n",
    "# deviation of 0 in the training set.\n",
    "x_train = x_train[:, std_nonzero_indices]\n",
    "x_validation = x_validation[:, std_nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.61635698  0.3836888  -0.07875145 ... -0.10382691 -0.10360927\n",
      "  -0.10469274]\n",
      " [-0.61635698  0.3836888  -0.07875145 ... -0.10382691 -0.10360927\n",
      "  -0.10469274]\n",
      " [-0.61635698  0.3836888  -0.07875145 ... -0.10382691 -0.10360927\n",
      "  -0.10469274]\n",
      " ...\n",
      " [-0.61635698  0.3836888  -0.07875145 ... -0.10382691 -0.10360927\n",
      "  -0.10469274]\n",
      " [-0.61635698  0.3836888  -0.07875145 ... -0.10382691 -0.10360927\n",
      "  -0.10469274]\n",
      " [-0.61635698  0.3836888  -0.07875145 ... -0.10382691 -0.10360927\n",
      "  -0.10469274]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor Initialization and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "rf = RandomForestRegressor(n_estimators=1000, n_jobs=-1, max_features=20,\n",
    "                           max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_train = rf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15768492, 0.3316633 , 0.08460946, ..., 0.27886429, 0.34164051,\n",
       "       0.0557242 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_output_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.4630632650087274\n",
      "Train auc: 0.9358616702522273\n"
     ]
    }
   ],
   "source": [
    "# Printing the accuracy of the model.\n",
    "train_score = rf.score(x_train, y_train)\n",
    "print('Train score:', train_score)\n",
    "train_auc = roc_auc_score(y_train, y_output_train)\n",
    "print('Train auc:', train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_lines = []\n",
    "for i in range(len(y_output_train)):\n",
    "    y_output_lines.append([i, y_output_train[i], y_train[i]])\n",
    "np.savetxt(\"2008_train_output.csv\", y_output_lines, fmt='%d,%f,%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.18074632848908068\n",
      "Validation auc: 0.7732541423466235\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of the model, according to the loss function specified in model.compile above.\n",
    "validation_score = rf.score(x_validation, y_validation)\n",
    "print('Validation score:', validation_score)\n",
    "y_output_validation = rf.predict(x_validation)\n",
    "validation_auc = roc_auc_score(y_validation, y_output_validation)\n",
    "print('Validation auc:', validation_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_lines = []\n",
    "for i in range(len(y_output_validation)):\n",
    "    y_output_lines.append([i, y_output_validation[i], y_validation[i]])\n",
    "np.savetxt(\"2008_validation_output.csv\", y_output_lines, fmt='%d,%f,%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7723558754239088"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(rf, data, label, cv=2, scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745233790616298"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(rf, data, label, cv=3, scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7759490259301046"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(rf, data, label, cv=4, scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Output 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2008 test data.\n",
    "X_test = load_data(\"test_2008.csv\")\n",
    "ids = X_test[:,0]\n",
    "x_test = X_test[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data.\n",
    "for j in range(len(x_test[0])):\n",
    "    test_std = np.std(x_test[:,j])\n",
    "    if test_std != 0:\n",
    "        x_test[:,j] = \\\n",
    "            np.divide(x_test[:,j] - np.mean(x_test[:,j]),\n",
    "                      np.std(x_test[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features from the data that have standard\n",
    "# deviation of 0 in the training set.\n",
    "x_test = x_test[:, std_nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_lines2 = []\n",
    "for i in range(len(y_output)):\n",
    "    y_output_lines2.append([i, y_output[i]])\n",
    "np.savetxt(\"2008_submission.csv\", y_output_lines2, fmt='%d,%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Output 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2012 test data.\n",
    "X_test2 = load_data(\"test_2012.csv\")\n",
    "ids2 = X_test2[:,0]\n",
    "x_test2 = X_test2[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data.\n",
    "for j in range(len(x_test2[0])):\n",
    "    test_std = np.std(x_test2[:,j])\n",
    "    if test_std != 0:\n",
    "        x_test2[:,j] = \\\n",
    "            np.divide(x_test2[:,j] - np.mean(x_test2[:,j]),\n",
    "                      np.std(x_test2[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features from the data that have standard\n",
    "# deviation of 0 in the training set.\n",
    "x_test2 = x_test2[:, std_nonzero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output2 = rf.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output_lines3 = []\n",
    "for i in range(len(y_output2)):\n",
    "    y_output_lines3.append([i, y_output2[i]])\n",
    "np.savetxt(\"2012_submission.csv\", y_output_lines3, fmt='%d,%f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
