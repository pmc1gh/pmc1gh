{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 155 Miniproject 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and divide it into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_data(\"train_2008.csv\")\n",
    "N = len(X)\n",
    "\n",
    "data = X[:, 3:-1]\n",
    "label = X[:, -1]\n",
    "\n",
    "train_percent = 70.\n",
    "train_size = int(N * train_percent / 100)\n",
    "\n",
    "x_train = data[0:train_size]\n",
    "y_train = label[0:train_size]\n",
    "x_test = data[train_size:]\n",
    "y_test = label[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64667, 383)\n"
     ]
    }
   ],
   "source": [
    "# print(N)\n",
    "# print(train_size)\n",
    "print(np.shape(X))\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1. 201.   0. ...   0.   0.   0.]\n",
      " [  1. 201.   0. ...   0.   0.   0.]\n",
      " [  1.   1.   0. ...   0.   0.   0.]\n",
      " ...\n",
      " [  2. 201.   0. ...   0.   0.   0.]\n",
      " [  1. 201.   0. ...   0.   0.   0.]\n",
      " [  1.   1.   0. ...   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels.\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n",
      "C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# don't forget to NORMALIZE\n",
    "train_mean_array = np.zeros(len(x_train[0]))\n",
    "train_std_array = np.zeros(len(x_train[0]))\n",
    "for j in range(len(x_train[0])):\n",
    "    train_mean_array[j] = np.mean(x_train[:,j])\n",
    "    train_std_array[j] = np.std(x_train[:,j])\n",
    "    x_train[:,j] = np.divide(x_train[:,j] - train_mean_array[j], train_std_array[j])\n",
    "    x_test[:,j] = np.divide(x_test[:,j] - np.mean(x_test[:,j]), np.std(x_test[:,j])) # use train metrics here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.61795939  0.38451965 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]\n",
      " [-0.61795939  0.38451965 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]\n",
      " [-0.61795939 -2.60061808 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]\n",
      " ...\n",
      " [ 0.57602003  0.38451965 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]\n",
      " [-0.61795939  0.38451965 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]\n",
      " [-0.61795939 -2.60061808 -0.07889334 ... -0.10360887 -0.10328175\n",
      "  -0.10426029]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the model here given the constraints in the problem.\n",
    "model = Sequential()\n",
    "model.add(Dense(400))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(400))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(loss='mse',\n",
    "               optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45266/45266 [==============================] - 7s 153us/step - loss: 0.2042 - acc: 0.7465 0s - loss: 0.2073 - ETA: 0s - loss: 0 - ETA: 0s - loss: \n",
      "Epoch 2/20\n",
      "45266/45266 [==============================] - 7s 148us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 3/20\n",
      "45266/45266 [==============================] - 10s 211us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 4/20\n",
      "45266/45266 [==============================] - 9s 200us/step - loss: 0.1892 - acc: 0.7465ETA\n",
      "Epoch 5/20\n",
      "45266/45266 [==============================] - 9s 204us/step - loss: 0.1892 - acc: 0.7465 2s - - ETA: 3s - lo\n",
      "Epoch 6/20\n",
      "45266/45266 [==============================] - 8s 170us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 7/20\n",
      "45266/45266 [==============================] - 5s 118us/step - loss: 0.1892 - acc: 0.7465TA: 0s - loss: 0.1893 - ac\n",
      "Epoch 8/20\n",
      "45266/45266 [==============================] - 8s 182us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 9/20\n",
      "45266/45266 [==============================] - 9s 199us/step - loss: 0.1892 - acc: 0.7465 ETA: - ETA: 0s - loss: 0.1895 - ac\n",
      "Epoch 10/20\n",
      "45266/45266 [==============================] - 6s 130us/step - loss: 0.1892 - acc: 0.7465 0s - loss: 0.1889  - ETA: \n",
      "Epoch 11/20\n",
      "45266/45266 [==============================] - 6s 143us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 12/20\n",
      "45266/45266 [==============================] - 9s 191us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 13/20\n",
      "45266/45266 [==============================] - 9s 197us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 14/20\n",
      "45266/45266 [==============================] - 5s 121us/step - loss: 0.1892 - acc: 0.7465 0s - loss:\n",
      "Epoch 15/20\n",
      "45266/45266 [==============================] - 7s 158us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 16/20\n",
      "45266/45266 [==============================] - 9s 206us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 17/20\n",
      "45266/45266 [==============================] - 9s 208us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 18/20\n",
      "45266/45266 [==============================] - 9s 194us/step - loss: 0.1892 - acc: 0.7465\n",
      "Epoch 19/20\n",
      "45266/45266 [==============================] - 5s 115us/step - loss: 0.1892 - acc: 0.7465 0s - loss: 0.1892 - acc\n",
      "Epoch 20/20\n",
      "45266/45266 [==============================] - 7s 159us/step - loss: 0.1892 - acc: 0.7465\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(x_train, y_train, batch_size=64, epochs=20,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x0000021793D0DE48>\n",
      "(None, 400)\n",
      "<keras.layers.core.Activation object at 0x0000021793D0DC88>\n",
      "(None, 400)\n",
      "<keras.layers.core.Dropout object at 0x0000021793D0D898>\n",
      "(None, 400)\n",
      "<keras.layers.core.Dense object at 0x0000021793D0D978>\n",
      "(None, 200)\n",
      "<keras.layers.core.Activation object at 0x0000021793D0D9B0>\n",
      "(None, 200)\n",
      "<keras.layers.core.Dropout object at 0x0000021793D0DA20>\n",
      "(None, 200)\n",
      "<keras.layers.core.Dense object at 0x0000021793D0DB00>\n",
      "(None, 400)\n",
      "<keras.layers.core.Activation object at 0x0000021793D0D780>\n",
      "(None, 400)\n",
      "<keras.layers.core.Dense object at 0x0000021793D0D710>\n",
      "(None, 2)\n",
      "<keras.layers.core.Activation object at 0x0000021793D0D828>\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "# why don't we take a look at the layers and outputs\n",
    "# note: `None` in the first dimension means it can take any batch_size!\n",
    "for i in range(len(model.layers)):\n",
    "    layer = model.layers[i]\n",
    "    print(layer)\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313402"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our model has some # of parameters:\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 400)               152000    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 400)               80400     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 802       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 313,402\n",
      "Trainable params: 313,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Printing a summary of the layers and weights in the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that our model outputs two eval params:\n",
    "# 1. loss (categorical cross-entropy)\n",
    "# 2. accuracy\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.1892175907183119\n",
      "Test accuracy: 0.7465426589519553\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of the model, according to the loss function specified in model.compile above.\n",
    "score = model.evaluate(x=x_train, y=y_train, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.19237427000016086\n",
      "Test accuracy: 0.7401164888469259\n"
     ]
    }
   ],
   "source": [
    "## Printing the accuracy of the model, according to the loss function specified in model.compile above.\n",
    "score = model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
