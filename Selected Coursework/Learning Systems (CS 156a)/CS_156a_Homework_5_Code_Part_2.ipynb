{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philip Carr\n",
    "# CS/CNS/EE_156a_Homework_5_Code_Part_2 (Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for The Logistic Regression Algorithm (Problems 8 and 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x):\n",
    "    '''\n",
    "    Return the sign of a number (1 if positive, 0 if 0, or -1 if\n",
    "    negative).\n",
    "    \n",
    "    Return type: int\n",
    "    '''\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function_line_value(x_point, y_point, m, b):\n",
    "    '''\n",
    "    Return the evaluation of the target function (line with slope m\n",
    "    and y-intercept b) for a given point (1, x_point, y_point) and\n",
    "    sign_orientation: determines whether points have value of 1 or -1\n",
    "    when above the target function line with this value being either\n",
    "    1 or -1 respectively.\n",
    "    \n",
    "    Return type: int\n",
    "    '''\n",
    "    y_line = m * x_point + b\n",
    "    if y_point >= y_line:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_function_line():\n",
    "    '''\n",
    "    Return a randomly generated target function line's slope (m) and\n",
    "    y-intercept (b).\n",
    "    \n",
    "    Return type: tuple of floats\n",
    "    '''\n",
    "    x1 = rn.uniform(-1, 1)\n",
    "    y1 = rn.uniform(-1, 1)\n",
    "    x2 = rn.uniform(-1, 1)\n",
    "    y2 = rn.uniform(-1, 1)\n",
    "    m = (y2 - y1) / (x2 - x1)\n",
    "    b = y1 - m * x1\n",
    "    return m, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_function():\n",
    "    '''\n",
    "    Return a randomly generated target function line.\n",
    "    \n",
    "    Return type: function that takes two floats and returns an int\n",
    "    (instance of the target_function_line_value function).\n",
    "    '''\n",
    "    m, b = get_target_function_line()\n",
    "    return m, b, lambda x_point, y_point: \\\n",
    "        target_function_line_value(x_point, y_point, m, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_points(N):\n",
    "    '''\n",
    "    Return a list of randomly generated points within\n",
    "    the region [-1, 1] x [-1, 1].\n",
    "    \n",
    "    Return type: list of points (each point is a list)\n",
    "    '''\n",
    "    random_points = []\n",
    "    for n in range(N):\n",
    "        x0 = 1.0 # artificial coordinate\n",
    "        x1 = rn.uniform(-1, 1)\n",
    "        x2 = rn.uniform(-1, 1)\n",
    "        random_points.append([x0, x1, x2])\n",
    "    return random_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_values(points, target_function):\n",
    "    '''\n",
    "    Return the values corresponding to the (list of) points given.\n",
    "    The returned values are function evaluations of the target\n",
    "    function target_function of the given points.\n",
    "    \n",
    "    Return type: list of ints\n",
    "    '''\n",
    "    point_values = []\n",
    "    for i in range(len(points)):\n",
    "        value = target_function(points[i][1], points[i][2])\n",
    "        point_values.append(value)\n",
    "    return point_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg:\n",
    "    '''\n",
    "    This class represents the LogReg (Logistic Regression Algorithm).\n",
    "    This class contains the weights, as well as methods for running\n",
    "    the Logistic Regression Algorithm.\n",
    "    '''\n",
    "    def __init__(self, n=2):\n",
    "        '''\n",
    "        Initialize the weights of the LogReg using the given\n",
    "        dimension n of the points to work with in R^n space.\n",
    "        \n",
    "        Return type: class (LogReg)\n",
    "        '''\n",
    "        self.weights = [0] * (n + 1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        '''\n",
    "        Print the weights of the LogReg.\n",
    "        \n",
    "        Return type: string\n",
    "        '''\n",
    "        print(\"LogReg weights:\", self.weights)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        '''\n",
    "        Return the weights of the LogReg.\n",
    "        \n",
    "        Return type: list of floats\n",
    "        '''\n",
    "        return self.weights\n",
    "    \n",
    "    def updated_weights(self, point, value, eta):\n",
    "        '''\n",
    "        Update the LogReg weights using the gradient given a point\n",
    "        and its corresponding target function value. Eta is the\n",
    "        learning rate.\n",
    "        \n",
    "        Return type: list of floats\n",
    "        '''\n",
    "        new_weights = []\n",
    "        gradE = [0] * len(self.weights)\n",
    "        # Calculate the gradient for each point and update the\n",
    "        # weights accordingly.\n",
    "        denominator_exp_term = 0.0\n",
    "        for i in range(len(point)):\n",
    "            denominator_exp_term += \\\n",
    "                self.weights[i] * point[i]\n",
    "        denominator_exp_term *= value\n",
    "        for i in range(len(point)):\n",
    "            gradE[i] = -1 * point[i] * value \\\n",
    "                       / (1 + np.exp(denominator_exp_term))\n",
    "        for i in range(len(point)):\n",
    "            new_weights.append(self.weights[i] - eta * gradE[i])\n",
    "        return new_weights\n",
    "\n",
    "    def get_weights_iteration_distance(self, current_weights,\n",
    "                                       new_weights):\n",
    "        '''\n",
    "        Return the Euclidean distance between two weight vectors.\n",
    "        '''\n",
    "        sum_of_squares = 0.0\n",
    "        for i in range(len(current_weights)):\n",
    "            weight_distance = (new_weights[i] - current_weights[i])\n",
    "            sum_of_squares += weight_distance * weight_distance\n",
    "        return np.sqrt(sum_of_squares)\n",
    "        \n",
    "    def run(self, points, values, max_epochs=1000, eta=0.01,\n",
    "            error_threshold=0.01):\n",
    "        '''\n",
    "        Return the number of iterations it takes to converge the\n",
    "        LogReg to minimize classification error given (list of)\n",
    "        points and (the list of) target function point values of the\n",
    "        given points (values).\n",
    "        \n",
    "        Return type: int\n",
    "        '''\n",
    "        n_epochs = 0\n",
    "        weights_iteration_distance = float(\"inf\")\n",
    "        N = len(points)\n",
    "        while weights_iteration_distance >= error_threshold \\\n",
    "              and n_epochs < max_epochs:\n",
    "            permutation_indices = np.random.permutation(N)\n",
    "            old_weights = list(np.copy(np.array(self.weights)))\n",
    "            for i in range(N):\n",
    "                point = points[permutation_indices[i]]\n",
    "                value = values[permutation_indices[i]]\n",
    "            \n",
    "                new_weights = self.updated_weights(point, value,\n",
    "                                                   eta)\n",
    "                self.weights = new_weights\n",
    "            \n",
    "            weights_iteration_distance = \\\n",
    "                self.get_weights_iteration_distance(old_weights,\n",
    "                                                    new_weights)\n",
    "            n_epochs += 1\n",
    "        return n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(trained_LR, N, t_function, points, values):\n",
    "    '''\n",
    "    Return the cross entropy error given a trained Logistic\n",
    "    Regression Algorithm, the number of points used, the target\n",
    "    function, the points, and the points' corresponding values.\n",
    "    '''\n",
    "    weights = trained_LR.get_weights()\n",
    "    term_sum = 0\n",
    "    for n in range(N):\n",
    "        exp_term = 0\n",
    "        for i in range(len(points[0])):\n",
    "            try:\n",
    "                exp_term += weights[i] * points[n][i]\n",
    "            except:\n",
    "                print(len(weights), len(points[n]))\n",
    "                raise ValueError(\"list index out of range\")\n",
    "        exp_term *= -values[n]\n",
    "        term_sum += np.log(1 + np.exp(exp_term))\n",
    "    return term_sum / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_E_out(trained_LR, N, t_function):\n",
    "    '''\n",
    "    Return the cross entropy error given a trained Logistic\n",
    "    Regression Algorithm for out-of-sample data.\n",
    "    '''\n",
    "    points = get_random_points(N)\n",
    "    values = get_point_values(points, t_function)\n",
    "    \n",
    "    return cross_entropy_error(trained_LR, N, t_function, points,\n",
    "                               values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_LogReg_error(N_in=100, N_out=1000):\n",
    "    '''\n",
    "    Return the number of iterations to converge and out-of-sample\n",
    "    error of a run of the Logistic Regression Algorithm.\n",
    "    '''\n",
    "    training_points = get_random_points(N_in)\n",
    "    m, b, t_function = get_target_function()\n",
    "    training_values = get_point_values(training_points, t_function)\n",
    "    LR = LogReg()\n",
    "    n_epochs = LR.run(training_points, training_values)\n",
    "    E_out = get_E_out(LR, N_out, t_function)\n",
    "    return n_epochs, E_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg_test(trials=1000, N_in=100, N_out=1000):\n",
    "    '''\n",
    "    Return the average number of iterations to converge and average\n",
    "    out-of-sample error of a run of the Logistic Regression\n",
    "    Algorithm over a given number of trials.\n",
    "    '''\n",
    "    n_epochs_sum = 0\n",
    "    E_out_sum = 0\n",
    "    for i in range(trials):\n",
    "        n_epochs, E_out = get_LogReg_error(N_in=N_in, N_out=N_out)\n",
    "        n_epochs_sum += n_epochs\n",
    "        E_out_sum += E_out\n",
    "    mean_n_epochs = n_epochs_sum / trials\n",
    "    mean_E_out = E_out_sum / trials\n",
    "    print(\"Mean E_out for N =\", N_in, \"for\", trials, \":\", mean_E_out)\n",
    "    print(\"Mean number of epochs to converge for N =\", N_in, \"for\",\n",
    "          trials, \"trials:\", mean_n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problems 8 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean E_out for N = 100 for 1000 : 0.10264816397345258\n",
      "Mean number of epochs to converge for N = 100 for 1000 trials: 343.102\n"
     ]
    }
   ],
   "source": [
    "LogReg_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
