{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philip Carr\n",
    "# CS/CNS/EE_156a_Homework_8_Code (Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for SVM With Soft Margins Section (Problems 2 - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rn\n",
    "import numpy as np\n",
    "\n",
    "# Package imported for SVM: Scikit-Learn sklearn.svm SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Scikit-Learn Cross Validation function\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_file(filename):\n",
    "    \"\"\"\n",
    "    Return an array of points of (intensity, symmetry)\n",
    "    and an array of corresponding values together as a tuple obtained\n",
    "    from the file with the given name filename.\n",
    "    \n",
    "    Dataset used: US Postal Service Zip Code data set\n",
    "    \n",
    "    Return type: 2D array of points\n",
    "    \"\"\"\n",
    "    file1 = open(filename, \"r\")\n",
    "    points = []\n",
    "    values = []\n",
    "    for line in file1:\n",
    "        data = line.split()\n",
    "        y = int(float(data[0])) # digit\n",
    "        x0 = float(data[1]) # intensity value\n",
    "        x1 = float(data[2]) # symmetry value\n",
    "        points.append([x0, x1])\n",
    "        values.append(y)\n",
    "    file1.close()\n",
    "    return (np.array(points, dtype=np.float64),\n",
    "            np.array(values, dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_vs_all_values(values, n):\n",
    "    \"\"\"\n",
    "    Return an array of values of 1 if the original value is equal\n",
    "    to n or -1 if not.\n",
    "    \"\"\"\n",
    "    new_values = []\n",
    "    for y in values:\n",
    "        if y == n:\n",
    "            new_values.append(1)\n",
    "        else:\n",
    "            new_values.append(-1)\n",
    "    return np.array(new_values, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_vs_m_data(points, values, n, m):\n",
    "    \"\"\"\n",
    "    Return a tuple of an array of points (corresponding to the\n",
    "    returned array of values) and an array of values of 1 if the\n",
    "    original value is equal to n or -1 if the original value is\n",
    "    equal to m. (x_vector, y) data with y values that do not equal\n",
    "    n or m are discarded from new returned dataset.\n",
    "    \"\"\"\n",
    "    new_points = []\n",
    "    new_values = []\n",
    "    for i in range(len(values)):\n",
    "        x = points[i]\n",
    "        y = values[i]\n",
    "        if y == n:\n",
    "            new_points.append(x)\n",
    "            new_values.append(1)\n",
    "        else:\n",
    "            if y == m:\n",
    "                new_points.append(x)\n",
    "                new_values.append(-1)\n",
    "    return (np.array(new_points, dtype=np.float64),\n",
    "            np.array(new_values, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_poly_n_vs_all_test(n_vs_all_list, svm_return, C=0.01, Q=2):\n",
    "    \"\"\"\n",
    "    Return in-sample errors of the SVM (Support Vector Machine)\n",
    "    with a polynomial kernel with degree Q after being trained on\n",
    "    the US Postal Service Zip Code data set.\n",
    "    \"\"\"\n",
    "    assert(len(n_vs_all_list) > 0)\n",
    "    assert(svm_return in [\"lowest\", \"highest\"])\n",
    "    \n",
    "    # Initialize training data.\n",
    "    training_points, training_values_original = \\\n",
    "        get_data_from_file(\"features.train\")\n",
    "    \n",
    "    min_E_in = float(\"inf\")\n",
    "    n_min_E_in = -1\n",
    "    svm_min_E_in = None\n",
    "    \n",
    "    max_E_in = -float(\"inf\")\n",
    "    n_max_E_in = -1\n",
    "    svm_max_E_in = None\n",
    "    for n in n_vs_all_list:\n",
    "        # Initialize training data.\n",
    "        training_values = \\\n",
    "            get_n_vs_all_values(training_values_original, n)\n",
    "    \n",
    "        # Initialize and fit SVM (Scikit-Learn SVC) to\n",
    "        # training data.\n",
    "        svc = SVC(C=C, kernel=\"poly\", degree=Q, gamma=1.0,\n",
    "                  coef0=1.0)\n",
    "        svc.fit(training_points, training_values)\n",
    "        \n",
    "        # Compute the in-sample classification error of the SVM.\n",
    "        svc_in_sample_error = 1.0 - \\\n",
    "            svc.score(training_points, training_values)\n",
    "        \n",
    "        print(\"In-sample error (E_in) for\", str(n) + \"-vs-all SVM:\",\n",
    "              svc_in_sample_error)\n",
    "        \n",
    "        # Check if min E_in found.\n",
    "        if svm_return == \"lowest\" \\\n",
    "           and svc_in_sample_error < min_E_in:\n",
    "            min_E_in = svc_in_sample_error\n",
    "            n_min_E_in = n\n",
    "            svm_min_E_in = svc\n",
    "            \n",
    "        # Check if max E_in found.\n",
    "        if svm_return == \"highest\" \\\n",
    "           and svc_in_sample_error > max_E_in:\n",
    "            max_E_in = svc_in_sample_error\n",
    "            n_max_E_in = n\n",
    "            svm_max_E_in = svc\n",
    "    \n",
    "    if svm_return == \"lowest\":\n",
    "        print(\"\\nSVM chosen with min E_in:\", str(n_min_E_in)\n",
    "          + \"-vs-all SVM\")\n",
    "        return svm_min_E_in\n",
    "    else:\n",
    "        print(\"\\nSVM chosen with max E_in:\", str(n_max_E_in)\n",
    "          + \"-vs-all SVM\")\n",
    "        return svm_max_E_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample error (E_in) for 0-vs-all SVM: 0.10588396653408316\n",
      "In-sample error (E_in) for 2-vs-all SVM: 0.10026059525442321\n",
      "In-sample error (E_in) for 4-vs-all SVM: 0.08942531888629812\n",
      "In-sample error (E_in) for 6-vs-all SVM: 0.09107118365107669\n",
      "In-sample error (E_in) for 8-vs-all SVM: 0.074338225209162\n",
      "\n",
      "SVM chosen with max E_in: 0-vs-all SVM\n"
     ]
    }
   ],
   "source": [
    "svm_prob2 = SVM_poly_n_vs_all_test([0, 2, 4, 6, 8], \"highest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample error (E_in) for 1-vs-all SVM: 0.014401316691811772\n",
      "In-sample error (E_in) for 3-vs-all SVM: 0.09024825126868741\n",
      "In-sample error (E_in) for 5-vs-all SVM: 0.07625840076807022\n",
      "In-sample error (E_in) for 7-vs-all SVM: 0.08846523110684401\n",
      "In-sample error (E_in) for 9-vs-all SVM: 0.08832807570977919\n",
      "\n",
      "SVM chosen with min E_in: 1-vs-all SVM\n"
     ]
    }
   ],
   "source": [
    "svm_prob3 = SVM_poly_n_vs_all_test([1, 3, 5, 7, 9], \"lowest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between the number of support vectors of the two selected classifiers from Problems 2 and 3: 1793\n"
     ]
    }
   ],
   "source": [
    "n_support_diff_2_3 = len(svm_prob2.support_) \\\n",
    "                     - len(svm_prob3.support_)\n",
    "print(\"Difference between the number of support vectors of the two\",\n",
    "      \"selected classifiers from Problems 2 and 3:\",\n",
    "      n_support_diff_2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_poly_n_vs_m_test1(n, m, C_list=[0.001, 0.01, 0.1, 1], Q=2):\n",
    "    \"\"\"\n",
    "    Iterate over the given values of C in C_list and print the\n",
    "    in-sample error, out-of-sample error, and number of support\n",
    "    vectors resulting using an n-vs-m SVM (Support Vector Machine)\n",
    "    with a polynomial kernel with degree Q after being trained on\n",
    "    the US Postal Service Zip Code data set.\n",
    "    \"\"\"\n",
    "    assert(n >= 0 and n <= 9)\n",
    "    assert(m >= 0 and m <= 9)\n",
    "    \n",
    "    print(str(n) + \"-vs-\" + str(m) + \" SVM with polynomial kernel,\",\n",
    "          \"Q = \" + str(Q) + \":\\n\")\n",
    "    \n",
    "    # Initialize training data.\n",
    "    training_points_original, training_values_original = \\\n",
    "        get_data_from_file(\"features.train\")\n",
    "    training_points, training_values = \\\n",
    "        get_n_vs_m_data(training_points_original,\n",
    "                        training_values_original, n, m)\n",
    "    # Initialize test data.\n",
    "    test_points_original, test_values_original = \\\n",
    "        get_data_from_file(\"features.test\")\n",
    "    test_points, test_values = \\\n",
    "        get_n_vs_m_data(test_points_original,\n",
    "                        test_values_original, n, m)\n",
    "    \n",
    "    for C in C_list:\n",
    "        # Initialize and fit SVM (Scikit-Learn SVC) to\n",
    "        # training data.\n",
    "        print(\"C =\", str(C) + \":\")\n",
    "        svc = SVC(C=C, kernel=\"poly\", degree=Q, gamma=1.0,\n",
    "                  coef0=1.0)\n",
    "        svc.fit(training_points, training_values) \n",
    "        \n",
    "        # Compute the in-sample classification error of the SVM.\n",
    "        svc_in_sample_error = 1.0 - \\\n",
    "            svc.score(training_points, training_values)\n",
    "        \n",
    "        print(\"In-sample error (E_in):\", svc_in_sample_error)\n",
    "        \n",
    "        # Compute the out-of-sample classification error of the SVM.\n",
    "        svc_out_sample_error = 1.0 - \\\n",
    "            svc.score(test_points, test_values)\n",
    "        \n",
    "        print(\"Out-of-sample error (E_out):\", svc_out_sample_error)\n",
    "        \n",
    "        print(\"Number of support vectors:\", str(len(svc.support_))\n",
    "              + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-vs-5 SVM with polynomial kernel, Q = 2:\n",
      "\n",
      "C = 0.001:\n",
      "In-sample error (E_in): 0.004484304932735439\n",
      "Out-of-sample error (E_out): 0.01650943396226412\n",
      "Number of support vectors: 76\n",
      "\n",
      "C = 0.01:\n",
      "In-sample error (E_in): 0.004484304932735439\n",
      "Out-of-sample error (E_out): 0.018867924528301883\n",
      "Number of support vectors: 34\n",
      "\n",
      "C = 0.1:\n",
      "In-sample error (E_in): 0.004484304932735439\n",
      "Out-of-sample error (E_out): 0.018867924528301883\n",
      "Number of support vectors: 24\n",
      "\n",
      "C = 1:\n",
      "In-sample error (E_in): 0.0032030749519538215\n",
      "Out-of-sample error (E_out): 0.018867924528301883\n",
      "Number of support vectors: 24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_poly_n_vs_m_test1(1, 5, C_list=[0.001, 0.01, 0.1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-vs-5 SVM with polynomial kernel, Q = 2:\n",
      "\n",
      "C = 0.0001:\n",
      "In-sample error (E_in): 0.008968609865470878\n",
      "Out-of-sample error (E_out): 0.01650943396226412\n",
      "Number of support vectors: 236\n",
      "\n",
      "C = 0.001:\n",
      "In-sample error (E_in): 0.004484304932735439\n",
      "Out-of-sample error (E_out): 0.01650943396226412\n",
      "Number of support vectors: 76\n",
      "\n",
      "C = 0.01:\n",
      "In-sample error (E_in): 0.004484304932735439\n",
      "Out-of-sample error (E_out): 0.018867924528301883\n",
      "Number of support vectors: 34\n",
      "\n",
      "C = 1:\n",
      "In-sample error (E_in): 0.0032030749519538215\n",
      "Out-of-sample error (E_out): 0.018867924528301883\n",
      "Number of support vectors: 24\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "1-vs-5 SVM with polynomial kernel, Q = 5:\n",
      "\n",
      "C = 0.0001:\n",
      "In-sample error (E_in): 0.004484304932735439\n",
      "Out-of-sample error (E_out): 0.018867924528301883\n",
      "Number of support vectors: 26\n",
      "\n",
      "C = 0.001:\n",
      "In-sample error (E_in): 0.004484304932735439\n",
      "Out-of-sample error (E_out): 0.021226415094339646\n",
      "Number of support vectors: 25\n",
      "\n",
      "C = 0.01:\n",
      "In-sample error (E_in): 0.0038436899423446302\n",
      "Out-of-sample error (E_out): 0.021226415094339646\n",
      "Number of support vectors: 23\n",
      "\n",
      "C = 1:\n",
      "In-sample error (E_in): 0.0032030749519538215\n",
      "Out-of-sample error (E_out): 0.021226415094339646\n",
      "Number of support vectors: 21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_poly_n_vs_m_test1(1, 5, C_list=[0.0001, 0.001, 0.01, 1], Q=2)\n",
    "print(\"-\" * 60 + \"\\n\")\n",
    "SVM_poly_n_vs_m_test1(1, 5, C_list=[0.0001, 0.001, 0.01, 1], Q=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_poly_n_vs_m_test2(n, m, C_list=[0.001, 0.01, 0.1, 1], Q=2,\n",
    "                          trials=100):\n",
    "    \"\"\"\n",
    "    Run the given number of trials and select the value of C in\n",
    "    C_list that yields the lowest cross-validation error using an\n",
    "    n-vs-m SVM (Support Vector Machine) with a polynomial kernel\n",
    "    with degree Q after being trained on the US Postal Service Zip\n",
    "    Code data set.\n",
    "    \"\"\"\n",
    "    assert(n >= 0 and n <= 9)\n",
    "    assert(m >= 0 and m <= 9)\n",
    "    C_dict = {}\n",
    "    for C in C_list:\n",
    "        C_dict[C] = [0, 0]\n",
    "    \n",
    "    print(str(n) + \"-vs-\" + str(m) + \" SVM with polynomial kernel,\",\n",
    "          \"Q = \" + str(Q) + \":\")\n",
    "    print(\"C values:\", str(C_list) + \"\\n\")\n",
    "    \n",
    "    # Initialize training data.\n",
    "    training_points_original, training_values_original = \\\n",
    "        get_data_from_file(\"features.train\")\n",
    "    training_points, training_values = \\\n",
    "        get_n_vs_m_data(training_points_original,\n",
    "                        training_values_original, n, m)\n",
    "    \n",
    "    for i in range(trials):\n",
    "        C_min_E_cv = -1\n",
    "        min_E_cv = float(\"inf\")\n",
    "        for C in C_list:\n",
    "            # Initialize SVM (Scikit-Learn SVC) to\n",
    "            # training data.\n",
    "            svc = SVC(C=C, kernel=\"poly\", degree=Q, gamma=1.0,\n",
    "                  coef0=1.0)\n",
    "            \n",
    "            # Compute the cross-validation error of the SVM.\n",
    "            svc_cross_val_error = 1 \\\n",
    "                - np.mean(cross_val_score(svc, training_points,\n",
    "                                          training_values,\n",
    "                                          cv=KFold(n_splits=10,\n",
    "                                                   shuffle=True)))\n",
    "            \n",
    "            if svc_cross_val_error < min_E_cv:\n",
    "                min_E_cv = svc_cross_val_error\n",
    "                C_min_E_cv = C\n",
    "            else:\n",
    "                if svc_cross_val_error == min_E_cv \\\n",
    "                   and C < C_min_E_cv:\n",
    "                    min_E_cv = svc_cross_val_error\n",
    "                    C_min_E_cv = C\n",
    "        C_dict[C_min_E_cv][0] += 1\n",
    "        C_dict[C_min_E_cv][1] += min_E_cv\n",
    "    \n",
    "    C_max_count = -1\n",
    "    max_count = -1\n",
    "    for C in C_dict:\n",
    "        count = C_dict[C][0]\n",
    "        print(\"Number of times C =\", C, \"chosen out of\", trials,\n",
    "              \"times:\", count)\n",
    "        if count > 0:\n",
    "            C_dict[C][1] /= count\n",
    "        if count > max_count:\n",
    "            C_max_count = C\n",
    "            max_count = count\n",
    "    \n",
    "    print(\"\\nValue of C selected most often: C =\", C_max_count)\n",
    "    print(\"Average cross-validation error of C selected most often\",\n",
    "          \"(C =\", str(C_max_count) + \") (averaged using\",\n",
    "          str(C_dict[C_max_count][0]) + \" trials): E_cv =\",\n",
    "          C_dict[C_max_count][1])\n",
    "    \n",
    "    return C_max_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-vs-5 SVM with polynomial kernel, Q = 2:\n",
      "C values: [0.0001, 0.001, 0.01, 0.1, 1]\n",
      "\n",
      "Number of times C = 0.0001 chosen out of 100 times: 0\n",
      "Number of times C = 0.001 chosen out of 100 times: 30\n",
      "Number of times C = 0.01 chosen out of 100 times: 34\n",
      "Number of times C = 0.1 chosen out of 100 times: 17\n",
      "Number of times C = 1 chosen out of 100 times: 19\n",
      "\n",
      "Value of C selected most often: C = 0.01\n",
      "Average cross-validation error of C selected most often (C = 0.01) (averaged using 34 trials): E_cv = 0.004463402215369208\n"
     ]
    }
   ],
   "source": [
    "C_max_count = SVM_poly_n_vs_m_test2(1, 5,\n",
    "                                    C_list=[0.0001, 0.001, 0.01,\n",
    "                                            0.1, 1],\n",
    "                                    Q=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-vs-5 SVM with polynomial kernel, Q = 2:\n",
      "C values: [0.01]\n",
      "\n",
      "Number of times C = 0.01 chosen out of 100 times: 100\n",
      "\n",
      "Value of C selected most often: C = 0.01\n",
      "Average cross-validation error of C selected most often (C = 0.01) (averaged using 100 trials): E_cv = 0.004683447656377596\n"
     ]
    }
   ],
   "source": [
    "C_max_count = SVM_poly_n_vs_m_test2(1, 5, C_list=[C_max_count], Q=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_rbf_n_vs_m_test(n, m, C_list=[0.01, 1, 100, 1e4, 1e6]):\n",
    "    \"\"\"\n",
    "    Iterate over the given values of C in C_list and print the\n",
    "    in-sample and out-of-sample errors using an n-vs-m SVM (Support\n",
    "    Vector Machine) with an rbf (radial basis function) kernel after\n",
    "    being trained on the US Postal Service Zip Code data set.\n",
    "    \"\"\"\n",
    "    assert(n >= 0 and n <= 9)\n",
    "    assert(m >= 0 and m <= 9)\n",
    "    \n",
    "    print(str(n) + \"-vs-\" + str(m) + \" SVM with rbf kernel:\\n\")\n",
    "    \n",
    "    # Initialize training data.\n",
    "    training_points_original, training_values_original = \\\n",
    "        get_data_from_file(\"features.train\")\n",
    "    training_points, training_values = \\\n",
    "        get_n_vs_m_data(training_points_original,\n",
    "                        training_values_original, n, m)\n",
    "    \n",
    "    # Initialize test data.\n",
    "    test_points_original, test_values_original = \\\n",
    "        get_data_from_file(\"features.test\")\n",
    "    test_points, test_values = \\\n",
    "        get_n_vs_m_data(test_points_original,\n",
    "                        test_values_original, n, m)\n",
    "    \n",
    "    for C in C_list:\n",
    "        # Initialize and fit SVM (Scikit-Learn SVC) to\n",
    "        # training data.\n",
    "        print(\"C =\", str(C) + \":\")\n",
    "        svc = SVC(C=C, kernel=\"rbf\", gamma=1.0)\n",
    "        svc.fit(training_points, training_values) \n",
    "        \n",
    "        # Compute the in-sample classification error of the SVM.\n",
    "        svc_in_sample_error = 1.0 - \\\n",
    "            svc.score(training_points, training_values)\n",
    "        \n",
    "        print(\"In-sample error (E_in):\", svc_in_sample_error)\n",
    "        \n",
    "        # Compute the out-of-sample classification error of the SVM.\n",
    "        svc_out_sample_error = 1.0 - \\\n",
    "            svc.score(test_points, test_values)\n",
    "        \n",
    "        print(\"Out-of-sample error (E_out):\",\n",
    "              str(svc_out_sample_error) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problems 9 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-vs-5 SVM with rbf kernel:\n",
      "\n",
      "C = 0.01:\n",
      "In-sample error (E_in): 0.0038436899423446302\n",
      "Out-of-sample error (E_out): 0.02358490566037741\n",
      "\n",
      "C = 1:\n",
      "In-sample error (E_in): 0.004484304932735439\n",
      "Out-of-sample error (E_out): 0.021226415094339646\n",
      "\n",
      "C = 100:\n",
      "In-sample error (E_in): 0.0032030749519538215\n",
      "Out-of-sample error (E_out): 0.018867924528301883\n",
      "\n",
      "C = 10000.0:\n",
      "In-sample error (E_in): 0.002562459961563124\n",
      "Out-of-sample error (E_out): 0.02358490566037741\n",
      "\n",
      "C = 1000000.0:\n",
      "In-sample error (E_in): 0.0006406149903908087\n",
      "Out-of-sample error (E_out): 0.02358490566037741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_rbf_n_vs_m_test(1, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
