{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philip Carr\n",
    "# CS/CNS/EE 156a Homework 7 Code Part 1 (Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for The Logistic Regression Algorithm (Problems 1 - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x):\n",
    "    \"\"\"\n",
    "    Return the sign of a number (1 if positive, 0 if 0, or -1 if\n",
    "    negative).\n",
    "    \n",
    "    Return type: int\n",
    "    \"\"\"\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_file(filename):\n",
    "    \"\"\"\n",
    "    Return an array of points within the region [-1, 1] x [-1, 1]\n",
    "    and an array of corresponding values together as a tuple obtained\n",
    "    from the file with the given name filename.\n",
    "    \n",
    "    Return type: 2D array of points\n",
    "    \"\"\"\n",
    "    file1 = open(filename, \"r\")\n",
    "    points = []\n",
    "    values = []\n",
    "    for line in file1:\n",
    "        data = line.split()\n",
    "        x0 = 1.0\n",
    "        x1 = float(data[0])\n",
    "        x2 = float(data[1])\n",
    "        points.append([x0, x1, x2])\n",
    "        values.append(float(data[2]))\n",
    "    file1.close()\n",
    "    return (np.array(points, dtype=np.float64),\n",
    "            np.array(values, dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_points(points):\n",
    "    \"\"\"\n",
    "    Return an array of points transformed using the nonlinear\n",
    "    transformation Î¦(1, x1, x2) = (1, x1, x2, x1^2, x2^2, x1 x2,\n",
    "    |x1 - x2|, |x1 + x2|).\n",
    "    \"\"\"\n",
    "    transformed_points = []\n",
    "    for i in range(len(points)):\n",
    "        point = []\n",
    "        point.append(points[i,0])\n",
    "        point.append(points[i,1])\n",
    "        point.append(points[i,2])\n",
    "        point.append(points[i,1] * points[i,1])\n",
    "        point.append(points[i,2] * points[i,2])\n",
    "        point.append(points[i,1] * points[i,2])\n",
    "        point.append(abs(points[i,1] - points[i,2]))\n",
    "        point.append(abs(points[i,1] + points[i,2]))\n",
    "        transformed_points.append(point)\n",
    "    return np.array(transformed_points, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg:\n",
    "    \"\"\"\n",
    "    This class represents the LinReg (Linear Regression Algorithm\n",
    "    with regularization). This class contains the weights, as\n",
    "    well as methods for running the Linear Regression Algorithm\n",
    "    with regularization.\n",
    "    \"\"\"\n",
    "    def __init__(self, n=7):\n",
    "        \"\"\"\n",
    "        Initialize the weights of the LinReg using the given\n",
    "        dimension n of the points to work with in R^n space.\n",
    "        \n",
    "        Return type: class (LinReg)\n",
    "        \"\"\"\n",
    "        self.weights = np.array([0] * (n + 1), dtype=np.float64)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Print the weights of the LinReg.\n",
    "        \n",
    "        Return type: string\n",
    "        \"\"\"\n",
    "        print(\"LogReg weights:\", self.weights)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        Return the weights of the LinReg.\n",
    "        \n",
    "        Return type: list of floats\n",
    "        \"\"\"\n",
    "        return self.weights\n",
    "    \n",
    "    def evaluate(self, point):\n",
    "        \"\"\"\n",
    "        Return a point's value using the Linear Regression\n",
    "        Algorithm's weights.\n",
    "        \"\"\"\n",
    "        real_value = 0\n",
    "        if type(point) != np.float64:\n",
    "            assert(len(self.weights) == len(point))\n",
    "            for i in range(len(self.weights)):\n",
    "                real_value += self.weights[i] * point[i]\n",
    "        else:\n",
    "            assert(type(self.weights) == np.float64)\n",
    "            real_value += self.weights * point\n",
    "            \n",
    "        return sign(real_value)\n",
    "    \n",
    "    def optimize_weights(self, points, values,\n",
    "                         regularization_k=None):\n",
    "        \"\"\"\n",
    "        Optimize the LinReg weights using linear regression.\n",
    "        Regularization is used when regularization_k is not\n",
    "        equal to None.\n",
    "        \n",
    "        Return type: None\n",
    "        \"\"\"\n",
    "        if len(points.shape) > 1:\n",
    "            ZTZ = np.dot(np.transpose(points), points)\n",
    "        \n",
    "            dimension = len(points[0])\n",
    "            I = np.identity(dimension)\n",
    "        \n",
    "            if regularization_k != None:\n",
    "                lmda = np.power(float(10), regularization_k)\n",
    "            else:\n",
    "                lmda = 0\n",
    "        \n",
    "            lmda_I = lmda * I\n",
    "        \n",
    "            ZTZ_plus_lmda_I_inv = np.linalg.inv(ZTZ + lmda_I)\n",
    "        \n",
    "            ZT_times_y = np.dot(np.transpose(points), values)\n",
    "        \n",
    "            self.weights = np.dot(ZTZ_plus_lmda_I_inv, ZT_times_y)\n",
    "        else:\n",
    "            ZTZ = np.dot(np.transpose(points), points)\n",
    "        \n",
    "            if regularization_k != None:\n",
    "                lmda = np.power(float(10), regularization_k)\n",
    "            else:\n",
    "                lmda = 0\n",
    "        \n",
    "            ZTZ_plus_lmda_I_inv = 1.0 / (ZTZ + lmda)\n",
    "        \n",
    "            ZT_times_y = np.dot(np.transpose(points), values)\n",
    "        \n",
    "            self.weights = ZTZ_plus_lmda_I_inv * ZT_times_y\n",
    "\n",
    "    def get_classification_error(self, points, values):\n",
    "        \"\"\"\n",
    "        Return the classification error of the Linear Regression\n",
    "        algorithm given the points and values.\n",
    "        \n",
    "        Return type: np.float64\n",
    "        \"\"\"\n",
    "        misclassified_list = []\n",
    "        for i in range(len(points)):\n",
    "            point = points[i]\n",
    "            if self.evaluate(point) == values[i]:\n",
    "                misclassified_list.append(0)\n",
    "            else:\n",
    "                misclassified_list.append(1)\n",
    "        \n",
    "        return np.mean(np.array(misclassified_list,\n",
    "                                dtype=np.float64))\n",
    "        \n",
    "    def run(self, in_sample_points, in_sample_values,\n",
    "            out_sample_points, out_sample_values,\n",
    "            regularization_k=None):\n",
    "        \"\"\"\n",
    "        Return the in-sample error and out-of-sample error of\n",
    "        the Linear Regression algorithm after optimizing the\n",
    "        weights of the algorithm using the given in-sample\n",
    "        data (in_sample_points and in_sample_values).\n",
    "        \n",
    "        Return type: tuple of np.float64 values \n",
    "        \"\"\"\n",
    "        self.optimize_weights(in_sample_points, in_sample_values,\n",
    "                              regularization_k=regularization_k)\n",
    "        in_sample_error = \\\n",
    "            self.get_classification_error(in_sample_points,\n",
    "                                          in_sample_values)\n",
    "        out_sample_error = \\\n",
    "            self.get_classification_error(out_sample_points,\n",
    "                                          out_sample_values)\n",
    "        return (in_sample_error, out_sample_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting in-sample and out-of-sample points and values from\n",
    "# respective files.\n",
    "in_sample_points_from_file, in_sample_values = \\\n",
    "    get_data_from_file(\"in.dta\")\n",
    "in_sample_points = \\\n",
    "    get_transformed_points(in_sample_points_from_file)\n",
    "\n",
    "out_sample_points_from_file, out_sample_values = \\\n",
    "    get_data_from_file(\"out.dta\")\n",
    "out_sample_points = \\\n",
    "    get_transformed_points(out_sample_points_from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 model validation set classification error: 0.4 \n",
      "\n",
      "k = 4 model validation set classification error: 0.4 \n",
      "\n",
      "k = 5 model validation set classification error: 0.1 \n",
      "\n",
      "k = 6 model validation set classification error: 0.4 \n",
      "\n",
      "k = 7 model validation set classification error: 0.6 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_train = 25\n",
    "n_validation = len(in_sample_points) - n_train\n",
    "\n",
    "train_points = in_sample_points[:n_train]\n",
    "train_values = in_sample_values[:n_train]\n",
    "\n",
    "validation_points = in_sample_points[-n_validation:]\n",
    "validation_values = in_sample_values[-n_validation:]\n",
    "\n",
    "LR3 = LinReg(n=1)\n",
    "train_error3, validation_error3 = \\\n",
    "    LR3.run(train_points[:,3], train_values,\n",
    "            validation_points[:,3], validation_values)\n",
    "\n",
    "LR4 = LinReg(n=1)\n",
    "train_error4, validation_error4 = \\\n",
    "    LR4.run(train_points[:,4], train_values,\n",
    "            validation_points[:,4], validation_values)\n",
    "\n",
    "LR5 = LinReg(n=1)\n",
    "train_error5, validation_error5 = \\\n",
    "    LR5.run(train_points[:,5], train_values,\n",
    "            validation_points[:,5], validation_values)\n",
    "\n",
    "LR6 = LinReg(n=1)\n",
    "train_error6, validation_error6 = \\\n",
    "    LR6.run(train_points[:,6], train_values,\n",
    "            validation_points[:,6], validation_values)\n",
    "\n",
    "LR7 = LinReg(n=1)\n",
    "train_error7, validation_error7 = \\\n",
    "    LR7.run(train_points[:,7], train_values,\n",
    "            validation_points[:,7], validation_values)\n",
    "\n",
    "print(\"k = 3 model validation set classification error:\",\n",
    "      validation_error3, \"\\n\")\n",
    "\n",
    "print(\"k = 4 model validation set classification error:\",\n",
    "      validation_error4, \"\\n\")\n",
    "\n",
    "print(\"k = 5 model validation set classification error:\",\n",
    "      validation_error5, \"\\n\")\n",
    "\n",
    "print(\"k = 6 model validation set classification error:\",\n",
    "      validation_error6, \"\\n\")\n",
    "\n",
    "print(\"k = 7 model validation set classification error:\",\n",
    "      validation_error7, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 model out-of-sample classification error: 0.472 \n",
      "\n",
      "k = 4 model out-of-sample classification error: 0.472 \n",
      "\n",
      "k = 5 model out-of-sample classification error: 0.168 \n",
      "\n",
      "k = 6 model out-of-sample classification error: 0.472 \n",
      "\n",
      "k = 7 model out-of-sample classification error: 0.528 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_sample_error3 = \\\n",
    "    LR3.get_classification_error(out_sample_points[:,3],\n",
    "                                 out_sample_values)\n",
    "out_sample_error4 = \\\n",
    "    LR4.get_classification_error(out_sample_points[:,4],\n",
    "                                 out_sample_values)\n",
    "out_sample_error5 = \\\n",
    "    LR5.get_classification_error(out_sample_points[:,5],\n",
    "                                 out_sample_values)\n",
    "out_sample_error6 = \\\n",
    "    LR6.get_classification_error(out_sample_points[:,6],\n",
    "                                 out_sample_values)\n",
    "out_sample_error7 = \\\n",
    "    LR7.get_classification_error(out_sample_points[:,7],\n",
    "                                 out_sample_values)\n",
    "\n",
    "print(\"k = 3 model out-of-sample classification error:\",\n",
    "      out_sample_error3, \"\\n\")\n",
    "\n",
    "print(\"k = 4 model out-of-sample classification error:\",\n",
    "      out_sample_error4, \"\\n\")\n",
    "\n",
    "print(\"k = 5 model out-of-sample classification error:\",\n",
    "      out_sample_error5, \"\\n\")\n",
    "\n",
    "print(\"k = 6 model out-of-sample classification error:\",\n",
    "      out_sample_error6, \"\\n\")\n",
    "\n",
    "print(\"k = 7 model out-of-sample classification error:\",\n",
    "      out_sample_error7, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 model validation set classification error: 0.44 \n",
      "\n",
      "k = 4 model validation set classification error: 0.44 \n",
      "\n",
      "k = 5 model validation set classification error: 0.2 \n",
      "\n",
      "k = 6 model validation set classification error: 0.44 \n",
      "\n",
      "k = 7 model validation set classification error: 0.56 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_train_2 = 10\n",
    "n_validation_2 = len(in_sample_points) - n_train_2\n",
    "\n",
    "train_points_2 = in_sample_points[-n_train_2:]\n",
    "train_values_2 = in_sample_values[-n_train_2:]\n",
    "\n",
    "validation_points_2 = in_sample_points[:n_validation_2]\n",
    "validation_values_2 = in_sample_values[:n_validation_2]\n",
    "\n",
    "for i in range(len(train_points_2)):\n",
    "    assert(train_points_2[i][1] == validation_points[i][1])\n",
    "for i in range(len(train_points)):\n",
    "    assert(train_points[i][1] == validation_points_2[i][1])\n",
    "\n",
    "LR3_2 = LinReg(n=1)\n",
    "train_error3_2, validation_error3_2 = \\\n",
    "    LR3_2.run(train_points_2[:,3], train_values_2,\n",
    "            validation_points_2[:,3], validation_values_2)\n",
    "\n",
    "LR4_2 = LinReg(n=1)\n",
    "train_error4_2, validation_error4_2 = \\\n",
    "    LR4_2.run(train_points_2[:,4], train_values_2,\n",
    "            validation_points_2[:,4], validation_values_2)\n",
    "\n",
    "LR5_2 = LinReg(n=1)\n",
    "train_error5_2, validation_error5_2 = \\\n",
    "    LR5_2.run(train_points_2[:,5], train_values_2,\n",
    "            validation_points_2[:,5], validation_values_2)\n",
    "\n",
    "LR6_2 = LinReg(n=1)\n",
    "train_error6_2, validation_error6_2 = \\\n",
    "    LR6_2.run(train_points_2[:,6], train_values_2,\n",
    "            validation_points_2[:,6], validation_values_2)\n",
    "\n",
    "LR7_2 = LinReg(n=1)\n",
    "train_error7_2, validation_error7_2 = \\\n",
    "    LR7_2.run(train_points_2[:,7], train_values_2,\n",
    "            validation_points_2[:,7], validation_values_2)\n",
    "\n",
    "print(\"k = 3 model validation set classification error:\",\n",
    "      validation_error3_2, \"\\n\")\n",
    "\n",
    "print(\"k = 4 model validation set classification error:\",\n",
    "      validation_error4_2, \"\\n\")\n",
    "\n",
    "print(\"k = 5 model validation set classification error:\",\n",
    "      validation_error5_2, \"\\n\")\n",
    "\n",
    "print(\"k = 6 model validation set classification error:\",\n",
    "      validation_error6_2, \"\\n\")\n",
    "\n",
    "print(\"k = 7 model validation set classification error:\",\n",
    "      validation_error7_2, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 model out-of-sample classification error: 0.472 \n",
      "\n",
      "k = 4 model out-of-sample classification error: 0.472 \n",
      "\n",
      "k = 5 model out-of-sample classification error: 0.168 \n",
      "\n",
      "k = 6 model out-of-sample classification error: 0.472 \n",
      "\n",
      "k = 7 model out-of-sample classification error: 0.528 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_sample_error3_2 = \\\n",
    "    LR3_2.get_classification_error(out_sample_points[:,3],\n",
    "                                   out_sample_values)\n",
    "out_sample_error4_2 = \\\n",
    "    LR4_2.get_classification_error(out_sample_points[:,4],\n",
    "                                   out_sample_values)\n",
    "out_sample_error5_2 = \\\n",
    "    LR5_2.get_classification_error(out_sample_points[:,5],\n",
    "                                   out_sample_values)\n",
    "out_sample_error6_2 = \\\n",
    "    LR6_2.get_classification_error(out_sample_points[:,6],\n",
    "                                   out_sample_values)\n",
    "out_sample_error7_2 = \\\n",
    "    LR7_2.get_classification_error(out_sample_points[:,7],\n",
    "                                   out_sample_values)\n",
    "\n",
    "print(\"k = 3 model out-of-sample classification error:\",\n",
    "      out_sample_error3_2, \"\\n\")\n",
    "\n",
    "print(\"k = 4 model out-of-sample classification error:\",\n",
    "      out_sample_error4_2, \"\\n\")\n",
    "\n",
    "print(\"k = 5 model out-of-sample classification error:\",\n",
    "      out_sample_error5_2, \"\\n\")\n",
    "\n",
    "print(\"k = 6 model out-of-sample classification error:\",\n",
    "      out_sample_error6_2, \"\\n\")\n",
    "\n",
    "print(\"k = 7 model out-of-sample classification error:\",\n",
    "      out_sample_error7_2, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models chosen in Problems 1 and 3: k = 5 model for both problems.\n",
      "Problem 1 (k = 5 model) out-of-sample classification error: 0.168\n",
      "Problem 3 (k = 5 model) out-of-sample classification error: 0.168\n"
     ]
    }
   ],
   "source": [
    "print(\"Models chosen in Problems 1 and 3: k = 5 model for both\",\n",
    "      \"problems.\")\n",
    "print(\"Problem 1 (k = 5 model) out-of-sample classification error:\",\n",
    "      out_sample_error5)\n",
    "print(\"Problem 3 (k = 5 model) out-of-sample classification error:\",\n",
    "      out_sample_error5_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
